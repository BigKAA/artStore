# –ü–ª–∞–Ω –º–∏–≥—Ä–∞—Ü–∏–∏: Geo-Distributed Capacity Management —Å Leader Election

**–°–æ–∑–¥–∞–Ω:** 2025-12-04
**–°—Ç–∞—Ç—É—Å:** Architecture Complete, Implementation Pending

## üéØ –¶–µ–ª–∏ –º–∏–≥—Ä–∞—Ü–∏–∏

1. –ü–µ—Ä–µ—Ö–æ–¥ –æ—Ç Redis-based push –º–æ–¥–µ–ª–∏ –∫ HTTP polling –º–æ–¥–µ–ª–∏
2. –ü–æ–¥–¥–µ—Ä–∂–∫–∞ Storage Elements –≤ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –¶–û–î (–±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ Redis)
3. –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ Ingester —Å Leader Election
4. –°–Ω–∏–∂–µ–Ω–∏–µ —Å–µ—Ç–µ–≤–æ–≥–æ —Ç—Ä–∞—Ñ–∏–∫–∞ –Ω–∞ 75%

## üìã –ü—Ä–æ–±–ª–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ—à–∞–µ–º

### –ü–µ—Ä–≤–∏—á–Ω–∞—è: Storage Elements –≤ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –¶–û–î
- –ù–µ –∏–º–µ—é—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–º—É Redis
- –ù–µ –º–æ–≥—É—Ç –∏–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ reverse proxy/PTF/WAF
- –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (Storage ‚Üí Redis ‚Üê Ingester) –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç

### –í—Ç–æ—Ä–∏—á–Ω–∞—è: –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ Ingester
- –ë–µ–∑ coordination: 4 Ingester √ó 100 SE = 1,152,000 requests/day
- –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ polling, waste resources
- –° Leader Election: 288,000 requests/day (75% reduction)

## üèóÔ∏è –¶–µ–ª–µ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Control Plane ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  N √ó Ingester (Leader Election via Redis)             ‚îÇ
‚îÇ  - 1 LEADER: Polling Storage Elements                 ‚îÇ
‚îÇ  - N-1 FOLLOWERS: Reading from shared Redis cache     ‚îÇ
‚îÇ                                                         ‚îÇ
‚îÇ  Redis (Shared):                                       ‚îÇ
‚îÇ  - capacity_monitor:leader_lock (TTL=30s)             ‚îÇ
‚îÇ  - capacity:{se_id} (TTL=600s)                        ‚îÇ
‚îÇ  - health:{se_id} (TTL=600s)                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ –¢–û–õ–¨–ö–û Leader polls   ‚îÇ
          ‚Üì                        ‚Üì
    Reverse Proxy / PTF / WAF
          ‚îÇ
          ‚Üì
    Storage Elements (DC1-5)
    GET /api/v1/capacity
```

## üìÖ Migration Phases

### Phase 1: Implementation (Sprint N+1) ‚Üê –¢–ï–ö–£–©–ê–Ø –§–ê–ó–ê

#### ‚úÖ COMPLETED
- [x] Storage Element: `/api/v1/capacity` endpoint
- [x] `CapacityService` (Local FS + S3 support)
- [x] Configuration fields (datacenter_location, s3_soft_capacity_limit)
- [x] Router registration
- [x] Comprehensive documentation

#### üöß TO DO
- [ ] `AdaptiveCapacityMonitor` service —Å Leader Election
- [ ] Leader Election logic (Redis SET NX EX)
- [ ] Leader/Follower modes
- [ ] `UploadService` retry logic + lazy update
- [ ] Health checks (minimum 1 edit Storage)
- [ ] Prometheus metrics (Leader + Polling)

### Phase 2: Testing (Sprint N+1, Week 2)

- [ ] Unit tests –¥–ª—è Leader Election logic
- [ ] Unit tests –¥–ª—è CapacityService
- [ ] Integration tests –¥–ª—è adaptive polling
- [ ] Integration tests –¥–ª—è failover scenarios
- [ ] Load tests (4 Ingester √ó 100 SE)
- [ ] Chaos testing (kill Leader, Redis failures)

### Phase 3: Parallel Run (Sprint N+2)

- [ ] Deploy AdaptiveCapacityMonitor (parallel —Å —Ç–µ–∫—É—â–µ–π Redis write –ª–æ–≥–∏–∫–æ–π)
- [ ] Storage Elements –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç –ø–∏—Å–∞—Ç—å –≤ Redis (compatibility)
- [ ] Monitoring: Leader transitions, poll metrics, cache consistency
- [ ] Validation: —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–≤—É—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
- [ ] Duration: 1 week minimum

### Phase 4: Cutover (Sprint N+3)

- [ ] Verify Leader Election stability (>99.9% uptime)
- [ ] Ingester —á–∏—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û –∏–∑ capacity cache
- [ ] –£–¥–∞–ª–∏—Ç—å Redis write logic –∏–∑ Storage Elements
- [ ] Cleanup —Å—Ç–∞—Ä—ã—Ö Redis keys
- [ ] Full production monitoring
- [ ] Rollback plan validation

## üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏

### Redis Cache Structure

```redis
# Leader Election
capacity_monitor:leader_lock = "ingester-instance-uuid"
TTL: 30s

# Capacity Data (–æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è Leader)
capacity:{se_id} = {
  "storage_id": "se-dc2-01",
  "mode": "rw",
  "capacity": {"total": ..., "used": ..., "available": ...},
  "health": "healthy",
  "last_update": "ISO8601"
}
TTL: 600s

# Health Status
health:{se_id} = "healthy" | "unhealthy: <reason>"
TTL: 600s

# Polling Metadata
capacity:{se_id}:last_poll = "ISO8601"
capacity:{se_id}:prev = {...}  # –î–ª—è adaptive logic
```

### Leader Election Logic

```python
# Atomic leadership acquisition
acquired = await redis.set(
    "capacity_monitor:leader_lock",
    instance_id,
    nx=True,  # SET only if NOT exists
    ex=30,    # Expire after 30s
)

# Leadership renewal (Leader only)
if is_leader:
    await redis.expire("capacity_monitor:leader_lock", 30)
```

### Automatic Failover Timeline

```
T=0s:   Ingester-01 LEADER (TTL=30s)
T=15s:  Ingester-01 crashes
T=30s:  Lock expires
T=31s:  Ingester-02 acquires lock ‚Üí becomes LEADER
        
Max failover time: 30s
Cache remains valid: 600s (TTL)
```

### Configuration Parameters

```bash
# Storage Element
STORAGE_ELEMENT_ID=se-dc2-01
STORAGE_DATACENTER_LOCATION=dc2
STORAGE_TYPE=local|s3
STORAGE_EXTERNAL_ENDPOINT=https://se-dc2-01.example.com
STORAGE_S3_SOFT_CAPACITY_LIMIT=10995116277760  # 10TB

# Ingester (NEW)
CAPACITY_MONITOR_LEADER_TTL=30
CAPACITY_MONITOR_BASE_INTERVAL=30
CAPACITY_MONITOR_MAX_INTERVAL=300
CAPACITY_MONITOR_HTTP_TIMEOUT=15
```

## üìä Prometheus Metrics

### Leader Election
- `capacity_monitor_leader_state{instance_id}` - 1=leader, 0=follower
- `capacity_monitor_leader_transitions_total{transition_type}` - acquired/lost/renewed
- `leader_lock_acquisition_duration_seconds` - latency

### Capacity Polling
- `capacity_poll_duration_seconds{storage_id, status}` - poll latency
- `capacity_poll_failures_total{storage_id, error_type}` - failures
- `lazy_update_triggers_total{storage_id, reason}` - stale cache events
- `storage_elements_available{mode}` - available SE count

## ‚ö†Ô∏è Known Limitations

1. **Leader Failover Window:** Max 30s –±–µ–∑ polling
   - Mitigation: Cache TTL=600s, lazy update

2. **Redis Dependency:** Redis down = no Leader Election
   - Mitigation: Redis HA (Sentinel), followers use stale cache

3. **Eventual Consistency:** 30s-5min capacity staleness
   - Mitigation: Lazy update –Ω–∞ 507 errors

## üîÑ Rollback Plan

### Phase 3 Rollback (Parallel Run)
1. Stop AdaptiveCapacityMonitor –Ω–∞ –≤—Å–µ—Ö Ingester
2. Storage Elements –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç Redis write (unchanged)
3. Ingester —á–∏—Ç–∞–µ—Ç –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ Redis source
4. Zero downtime rollback

### Phase 4 Rollback (After Cutover)
1. Re-enable Redis write –Ω–∞ Storage Elements
2. Restart Storage Elements
3. Switch Ingester back to old Redis source
4. Stop AdaptiveCapacityMonitor
5. Expected downtime: 5-10 minutes

## üìö –°—Å—ã–ª–∫–∏

- **Documentation:** `claudedocs/geo-distributed-capacity-management-solution.md`
- **Storage Element endpoint:** `storage-element/app/api/v1/endpoints/capacity.py`
- **Capacity Service:** `storage-element/app/services/capacity_service.py`
- **Configuration:** `storage-element/app/core/config.py`

## ‚úÖ Success Criteria

### Phase 2 (Testing)
- [ ] 100% unit test coverage –¥–ª—è Leader Election
- [ ] Failover time < 35s –≤ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–∞—Ö
- [ ] Zero data loss –ø—Ä–∏ failover
- [ ] 100 SE polling –≤ < 60s

### Phase 3 (Parallel Run)
- [ ] Leader Election uptime > 99.9%
- [ ] Cache consistency > 99%
- [ ] No impact on upload latency
- [ ] Traffic reduction visible in metrics

### Phase 4 (Cutover)
- [ ] Zero downtime migration
- [ ] 75% traffic reduction confirmed
- [ ] All alerts configured and tested
- [ ] Runbook documented and validated
