# Implementation Plan: Storage Selection & Lifecycle Management

## –û–±–∑–æ—Ä

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–∏—Å—Ç–µ–º—ã –≤—ã–±–æ—Ä–∞ Storage Elements –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∂–∏–∑–Ω–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ ArtStore.

**–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è**: 2025-12-01
**–°—Ç–∞—Ç—É—Å**: Phase 3 (Sprint 16) - COMPLETED ‚úÖ
**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç**: High
**–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ**: 2025-12-02

**Sprint 16 Progress**:
- ‚úÖ Task 3.1: GarbageCollector Background Job - DONE
- ‚úÖ Task 3.2: Storage Element Delete API - DONE

---

## –ü—Ä–æ–±–ª–µ–º—ã –¥–ª—è —Ä–µ—à–µ–Ω–∏—è

### –ü—Ä–æ–±–ª–µ–º–∞ 1: –í—ã–±–æ—Ä RW Storage Element –ø—Ä–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥—É–ª—è—Ö

**–ö–æ–Ω—Ç–µ–∫—Å—Ç**: –í —Å–∏—Å—Ç–µ–º–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ Storage Elements –≤ —Ä–µ–∂–∏–º–µ `rw` (read-write). –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º –≤—ã–±–æ—Ä–∞ —Ü–µ–ª–µ–≤–æ–≥–æ SE –¥–ª—è –∑–∞–ø–∏—Å–∏ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤.

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**:
- Sequential Fill —Å—Ç—Ä–∞—Ç–µ–≥–∏—è ‚Äî –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ SE –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è capacity threshold
- Graceful degradation –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Redis (fallback –Ω–∞ Admin Module)
- Alert + Reject –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö SE
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ SE –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

### –ü—Ä–æ–±–ª–µ–º–∞ 2: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ Edit vs RW Storage –∏ –∂–∏–∑–Ω–µ–Ω–Ω—ã–π —Ü–∏–∫–ª –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤

**–ö–æ–Ω—Ç–µ–∫—Å—Ç**: –°–∏—Å—Ç–µ–º–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ç–∏–ø–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è:
- **Edit SE** ‚Äî –¥–æ–∫—É–º–µ–Ω—Ç—ã "–≤ —Ä–∞–±–æ—Ç–µ" (draft, work-in-progress)
- **RW SE** ‚Äî —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (accepted, permanent)

**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è**:
- Explicit —É–∫–∞–∑–∞–Ω–∏–µ retention policy –ø—Ä–∏ upload
- API –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ (–ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è temporary ‚Üí permanent)
- Two-Phase Commit –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–≥–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è garbage collection –¥–ª—è Edit SE

---

## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è

### 1. Sequential Fill —á–µ—Ä–µ–∑ Redis Registry

**–ü–æ—á–µ–º—É —ç—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **–î–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–∞—Ü–∏—è**: Ingester —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ –≤—ã–±–∏—Ä–∞–µ—Ç SE –±–µ–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ —Å Admin Module
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**: –ù–µ—Å–∫–æ–ª—å–∫–æ Ingester –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
- **–ì–∏–±–∫–æ—Å—Ç—å**: –ü–æ—Ä—è–¥–æ–∫ SE –ª–µ–≥–∫–æ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ priority –≤ Redis
- **–ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å**: O(log N) complexity –¥–ª—è –≤—ã–±–æ—Ä–∞ SE —á–µ—Ä–µ–∑ Sorted Set

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –æ—Ç–∫–ª–æ–Ω–µ–Ω—ã**:
- **Hardcoded –ø–æ—Ä—è–¥–æ–∫ SE** ‚Äî –Ω–µ–≥–∏–±–∫–æ—Å—Ç—å –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –Ω–æ–≤—ã—Ö SE
- **Admin Module –∫–∞–∫ coordinator** ‚Äî —Å–æ–∑–¥–∞—ë—Ç bottleneck –∏ single point of failure
- **Round Robin –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞** ‚Äî –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é Sequential Fill

**–ü–æ—á–µ–º—É Redis, –∞ –Ω–µ PostgreSQL?**

‚úÖ **Redis**:
- –ù–∏–∑–∫–∞—è latency (~1ms) –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—É—Ç–∏ upload
- Pub/Sub –¥–ª—è real-time updates —Å—Ç–∞—Ç—É—Å–∞ SE
- Sorted Set –¥–ª—è efficient ordering –ø–æ priority
- Atomic operations –¥–ª—è consistency

‚ùå **PostgreSQL**:
- –ë–æ–ª–µ–µ –≤—ã—Å–æ–∫–∞—è latency (~5-10ms) –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
- –ù–µ—Ç native Pub/Sub –¥–ª—è real-time updates
- –°–ª–æ–∂–Ω–µ–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å efficient priority-based querying

**Redis Schema Design**:

```redis
# –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥–æ–≥–æ Storage Element
Key: storage:elements:{se_id}
Type: Hash
Fields:
  - id: se_id (—É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä)
  - mode: rw | ro | ar | edit
  - capacity_total: bytes (–æ–±—â–∞—è capacity)
  - capacity_used: bytes (–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è capacity)
  - capacity_percent: float 0-100 (% –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç–∏)
  - endpoint: http://se-host:port (URL –¥–ª—è –¥–æ—Å—Ç—É–ø–∞)
  - priority: int (–º–µ–Ω—å—à–µ = –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
  - last_updated: timestamp (–≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è)
  - health_status: healthy | degraded | unavailable

# Sorted Set –¥–ª—è RW Storage Elements
Key: storage:rw:by_priority
Type: Sorted Set
Score: priority (–º–µ–Ω—å—à–µ = –≤—ã—à–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
Member: se_id

# Sorted Set –¥–ª—è Edit Storage Elements
Key: storage:edit:by_priority
Type: Sorted Set
Score: priority
Member: se_id
```

**–ü–æ—á–µ–º—É —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –¥–≤–∞ Sorted Set (rw –∏ edit)?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- –ë—ã—Å—Ç—Ä—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ä–µ–∂–∏–º—É –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
- –†–∞–∑–Ω—ã–µ capacity thresholds –¥–ª—è RW (95%) –∏ Edit (90%)
- –ù–µ–∑–∞–≤–∏—Å–∏–º–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ priority –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ storage
- –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞ –≤ Ingester

### 2. Health Reporting –æ—Ç Storage Elements

**–ü–æ—á–µ–º—É Storage Element —Å–∞–º –ø—É–±–ª–∏–∫—É–µ—Ç —Å—Ç–∞—Ç—É—Å?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **Decoupling**: SE –Ω–µ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç Admin Module –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–∞
- **Real-time updates**: –ò–∑–º–µ–Ω–µ–Ω–∏—è capacity –≤–∏–¥–Ω—ã –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ
- **Autonomy**: SE —Å–∞–º –∑–Ω–∞–µ—Ç —Å–≤–æ—é capacity –ª—É—á—à–µ –≤—Å–µ—Ö
- **Fault tolerance**: SE –º–æ–∂–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ Admin –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: Admin Module –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –æ–ø—Ä–∞—à–∏–≤–∞–µ—Ç SE**:
- –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –Ω–∞–≥—Ä—É–∑–∫—É –Ω–∞ Admin Module
- –ó–∞–¥–µ—Ä–∂–∫–∞ –≤ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Å—Ç–∞—Ç—É—Å–∞ (polling interval)
- Admin —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è critical path –¥–ª—è updates

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã Health Reporting**:

| –ü–∞—Ä–∞–º–µ—Ç—Ä | –ó–Ω–∞—á–µ–Ω–∏–µ | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ |
|----------|----------|-------------|
| **Report interval** | 30 —Å–µ–∫—É–Ω–¥ | –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ –Ω–∞–≥—Ä—É–∑–∫–æ–π –Ω–∞ Redis |
| **Staleness threshold** | 2 –º–∏–Ω—É—Ç—ã | 4x report interval –¥–ª—è —É—á—ë—Ç–∞ —Å–µ—Ç–µ–≤—ã—Ö –∑–∞–¥–µ—Ä–∂–µ–∫ |
| **Retry interval –ø—Ä–∏ –æ—à–∏–±–∫–µ** | 5 —Å–µ–∫—É–Ω–¥ | –ë—ã—Å—Ç—Ä–æ–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–±–æ–µ–≤ |

**–ü–æ—á–µ–º—É 30 —Å–µ–∫—É–Ω–¥ –¥–ª—è report interval?**

‚úÖ **30 —Å–µ–∫—É–Ω–¥**:
- –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∞—Å—Ç–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–ª—è capacity monitoring
- –ù–∏–∑–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ Redis (~2 writes/min –Ω–∞ SE)
- –ü—Ä–∏–µ–º–ª–µ–º–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è Sequential Fill (–Ω–æ–≤—ã–π SE –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç—Å—è —á–µ—Ä–µ–∑ 30 —Å–µ–∫)

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã**:
- **5-10 —Å–µ–∫—É–Ω–¥**: –ò–∑–±—ã—Ç–æ—á–Ω–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ Redis –±–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–π –ø–æ–ª—å–∑—ã
- **60+ —Å–µ–∫—É–Ω–¥**: –°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è –Ω–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è capacity

### 3. Adaptive Capacity Thresholds

**–ü—Ä–æ–±–ª–µ–º–∞ —Å —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ thresholds**:

–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç–Ω—ã–π threshold –Ω–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –¥–ª—è Storage Elements —Ä–∞–∑–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞:

| SE Size | Fixed 95% | Free Space | Assessment |
|---------|-----------|------------|------------|
| 1TB | 95% | 50GB | ‚úÖ Acceptable |
| 10TB | 95% | 500GB | ‚ö†Ô∏è Moderate waste |
| 100TB | 95% | 5TB | ‚ùå Significant waste |
| 1PB | 95% | 50TB | ‚ùå **CRITICAL waste** |

**–†–µ—à–µ–Ω–∏–µ: Adaptive Threshold Strategy**

–í–º–µ—Å—Ç–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ–Ω—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º **–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–∞—Å—á—ë—Ç** –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–±—Å–æ–ª—é—Ç–Ω–æ–≥–æ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ free space:

```python
def calculate_adaptive_threshold(total_capacity_bytes: int, mode: str) -> dict:
    """
    –†–∞—Å—Å—á–∏—Ç–∞—Ç—å adaptive threshold –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ SE.

    –î–ª—è RW:
    - –ú–∏–Ω–∏–º—É–º 50GB –∏–ª–∏ 2% –æ—Ç capacity (—á—Ç–æ –±–æ–ª—å—à–µ)
    - Warning: 15% –∏–ª–∏ 150GB free
    - Critical: 8% –∏–ª–∏ 80GB free
    - Full: 2% –∏–ª–∏ 20GB free

    –î–ª—è Edit (–±–æ–ª–µ–µ aggressive):
    - –ú–∏–Ω–∏–º—É–º 30GB –∏–ª–∏ 1% –æ—Ç capacity
    - Warning: 10% –∏–ª–∏ 100GB free
    - Critical: 5% –∏–ª–∏ 50GB free
    - Full: 1% –∏–ª–∏ 10GB free
    """
    total_gb = total_capacity_bytes / (1024**3)

    if mode == "rw":
        warning_free_gb = max(total_gb * 0.15, 150)
        critical_free_gb = max(total_gb * 0.08, 80)
        full_free_gb = max(total_gb * 0.02, 20)
    elif mode == "edit":
        warning_free_gb = max(total_gb * 0.10, 100)
        critical_free_gb = max(total_gb * 0.05, 50)
        full_free_gb = max(total_gb * 0.01, 10)

    return {
        "warning_threshold": (total_gb - warning_free_gb) / total_gb * 100,
        "critical_threshold": (total_gb - critical_free_gb) / total_gb * 100,
        "full_threshold": (total_gb - full_free_gb) / total_gb * 100,
        "warning_free_gb": warning_free_gb,
        "critical_free_gb": critical_free_gb,
        "full_free_gb": full_free_gb
    }
```

**–ü—Ä–∏–º–µ—Ä—ã –∞–¥–∞–ø—Ç–∏–≤–Ω—ã—Ö thresholds –¥–ª—è RW Storage**:

| SE Size | Warning | Critical | Full | Free @ Full | Waste % |
|---------|---------|----------|------|-------------|---------|
| 1TB | 85% (150GB) | 92% (80GB) | 98% (20GB) | 20GB | 2% |
| 10TB | 98.5% (150GB) | 99.2% (80GB) | 99.8% (20GB) | 20GB | 0.2% |
| 100TB | 98.5% (1.5TB) | 99.2% (800GB) | 99.8% (200GB) | 200GB | 0.2% |
| 1PB | 98.5% (15TB) | 99.2% (8TB) | 99.8% (2TB) | 2TB | 0.2% |

**–ü—Ä–∏–º–µ—Ä—ã –¥–ª—è Edit Storage** (–±–æ–ª–µ–µ aggressive):

| SE Size | Warning | Critical | Full | Free @ Full | Waste % |
|---------|---------|----------|------|-------------|---------|
| 1TB | 90% (100GB) | 95% (50GB) | 99% (10GB) | 10GB | 1% |
| 10TB | 99% (100GB) | 99.5% (50GB) | 99.9% (10GB) | 10GB | 0.1% |
| 100TB | 99% (1TB) | 99.5% (500GB) | 99.9% (100GB) | 100GB | 0.1% |

**–ü–æ—á–µ–º—É —ç—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **–ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ –ª—é–±–æ–º—É —Ä–∞–∑–º–µ—Ä—É SE
- **Efficiency**: –ú–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ—Ç waste space –Ω–∞ –±–æ–ª—å—à–∏—Ö SE (98%+ utilization)
- **Safety**: –ó–∞—â–∏—â–∞–µ—Ç –º–∞–ª—ã–µ SE (–º–∏–Ω–∏–º—É–º 50GB/30GB free)
- **Predictability**: –ê–±—Å–æ–ª—é—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–Ω—è—Ç–Ω–µ–µ –¥–ª—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤
- **No configuration**: –ù–µ —Ç—Ä–µ–±—É–µ—Ç manual tuning –¥–ª—è –∫–∞–∂–¥–æ–≥–æ SE

‚ùå **–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ—Ü–µ–Ω—Ç**:
- –ù–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ—Ç—Å—è –¥–ª—è –±–æ–ª—å—à–∏—Ö SE
- Waste —Ä–∞—Å—Ç—ë—Ç –ª–∏–Ω–µ–π–Ω–æ —Å —Ä–∞–∑–º–µ—Ä–æ–º
- –¢—Ä–µ–±—É–µ—Ç manual adjustment –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–æ–≤

### 3.1. Multi-Level Capacity Status

–í–º–µ—Å—Ç–æ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ "ok/reject" –∏—Å–ø–æ–ª—å–∑—É–µ–º **graduated response** —Å —á–µ—Ç—ã—Ä—å–º—è —Å—Ç–∞—Ç—É—Å–∞–º–∏:

```python
class CapacityStatus(Enum):
    OK = "ok"              # Normal operation
    WARNING = "warning"    # Approaching threshold, alert admin
    CRITICAL = "critical"  # Very close to full, urgent action needed
    FULL = "full"          # Reject new writes, switch to next SE
```

**–ü–æ–≤–µ–¥–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –ø–æ —Å—Ç–∞—Ç—É—Å–∞–º**:

| Status | Capacity | Ingester Behaviour | Alerting | Logging | Admin UI |
|--------|----------|-------------------|----------|---------|----------|
| **OK** | < warning | ‚úÖ Accept writes | ‚Äî | INFO | üü¢ Green |
| **WARNING** | ‚â• warning | ‚úÖ Accept writes | ‚ö†Ô∏è Low priority | WARNING | üü° Yellow |
| **CRITICAL** | ‚â• critical | ‚úÖ Accept writes | üö® High priority | ERROR | üü† Orange |
| **FULL** | ‚â• full | ‚ùå Skip SE, try next | üö® Critical page | CRITICAL | üî¥ Red |

**–ö–ª—é—á–µ–≤–æ–µ –æ—Ç–ª–∏—á–∏–µ**:
- WARNING –∏ CRITICAL –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç –ø—Ä–∏–Ω–∏–º–∞—Ç—å –∑–∞–ø–∏—Å–∏, —Ç–æ–ª—å–∫–æ –∞–ª–µ—Ä—Ç—è—Ç
- FULL ‚Äî –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å, –∫–æ–≥–¥–∞ SE –∏—Å–∫–ª—é—á–∞–µ—Ç—Å—è –∏–∑ Sequential Fill
- –≠—Ç–æ –¥–∞—ë—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –≤—Ä–µ–º—è –¥–ª—è —Ä–µ–∞–∫—Ü–∏–∏ –±–µ–∑ impact –Ω–∞ availability

**–ü–æ—á–µ–º—É graduated response?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **Proactive alerting**: –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä —É–∑–Ω–∞—ë—Ç –æ –ø—Ä–æ–±–ª–µ–º–µ –∑–∞—Ä–∞–Ω–µ–µ
- **No downtime**: –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–∏ warning/critical
- **Time to react**: –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è capacity
- **Better visibility**: –ß—ë—Ç–∫–∞—è –≥—Ä–∞–¥–∞—Ü–∏—è severity

‚ùå **Binary ok/reject**:
- –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä —É–∑–Ω–∞—ë—Ç –æ –ø—Ä–æ–±–ª–µ–º–µ —Å–ª–∏—à–∫–æ–º –ø–æ–∑–¥–Ω–æ
- –í–Ω–µ–∑–∞–ø–Ω—ã–π reject –±–µ–∑ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
- –ù–µ—Ç –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø–ª–∞–Ω–æ–≤—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π

### 3.2. Intelligent File Size Handling

**–ü—Ä–æ–±–ª–µ–º–∞**: –ü—Ä–∏ streaming upload —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ —á–∞—Å—Ç–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø–µ—Ä–µ–¥–∞—á–∏.

**–°—Ü–µ–Ω–∞—Ä–∏–π –ø—Ä–æ–±–ª–µ–º—ã**:
```
Client ‚Üí Ingester: POST /upload (chunked transfer encoding)
Ingester ‚Üí Storage Element: streaming upload
Storage Element: disk full –ø—Ä–∏ 90% upload ‚Üí error
Result: Wasted bandwidth + time + partial file cleanup
```

**–†–µ—à–µ–Ω–∏–µ: Pre-flight Check + Optimistic Retry**

```python
async def upload_with_intelligent_fallback(
    file: UploadFile,
    retention_policy: str,
    storage_selector: StorageSelector
) -> str:
    """Upload —Å intelligent fallback –ø—Ä–∏ insufficient space."""

    # 1. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
    file_size = None
    if hasattr(file, 'size'):
        file_size = file.size
    elif 'Content-Length' in request.headers:
        file_size = int(request.headers['Content-Length'])

    # 2. –í—ã–±—Ä–∞—Ç—å SE —Å pre-flight check (–µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –∏–∑–≤–µ—Å—Ç–µ–Ω)
    attempts = 0
    max_attempts = 3  # –î–æ 3 –ø–æ–ø—ã—Ç–æ–∫ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö SE

    while attempts < max_attempts:
        target_se = await storage_selector.select_storage_element(
            retention_policy=retention_policy,
            required_free_space=file_size  # Pre-flight check
        )

        if not target_se:
            raise HTTPException(503, "No available storage")

        try:
            # 3. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å upload
            file_id = await storage_client.upload_file(
                storage_element=target_se,
                file=file,
                retention_policy=retention_policy
            )

            # Success!
            return file_id

        except InsufficientSpaceError as e:
            # 4. Disk full ‚Üí retry –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º SE
            logger.warning(
                f"Upload failed on {target_se['id']}, retrying",
                extra={
                    "se_id": target_se["id"],
                    "attempt": attempts + 1,
                    "file_size": file_size
                }
            )

            # –í—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–º–µ—Ç–∏—Ç—å SE –∫–∞–∫ full
            await storage_selector.mark_se_temporarily_full(target_se["id"])

            attempts += 1
            continue

    # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
    raise HTTPException(503, "Failed to upload after multiple attempts")
```

**–õ–æ–≥–∏–∫–∞ Pre-flight Check –≤ StorageSelector**:

```python
async def select_storage_element(
    self,
    retention_policy: str,
    required_free_space: Optional[int] = None
) -> Optional[dict]:
    """
    –í—ã–±—Ä–∞—Ç—å SE —Å —É—á—ë—Ç–æ–º required_free_space.

    Args:
        required_free_space: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ free space –≤ bytes (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ)
    """
    # ... (–ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ SE –ø–æ priority)

    for se_id in se_ids:
        se_data = await self.redis.hgetall(f"storage:elements:{se_id}")

        # Skip SE –≤ —Å—Ç–∞—Ç—É—Å–µ FULL
        if se_data.get("capacity_status") == "full":
            continue

        # Pre-flight check: –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –º–µ—Å—Ç–∞?
        if required_free_space:
            free_bytes = (
                int(se_data["capacity_total"]) -
                int(se_data["capacity_used"])
            )

            if free_bytes < required_free_space:
                logger.debug(f"SE {se_id} skipped: insufficient space")
                continue  # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–π SE

        # SE –ø–æ–¥—Ö–æ–¥–∏—Ç
        return se_data

    return None  # –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö SE
```

**–ü–æ—á–µ–º—É —ç—Ç–æ—Ç –ø–æ–¥—Ö–æ–¥?**

‚úÖ **Pre-flight check** (–µ—Å–ª–∏ Content-Length –∏–∑–≤–µ—Å—Ç–µ–Ω):
- –ò–∑–±–µ–≥–∞–µ—Ç wasted bandwidth –ø—Ä–∏ upload –≤ –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–π SE
- –ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏–π SE
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Å–ª—É—á–∞–µ–≤ –∫–æ–≥–¥–∞ —Ä–∞–∑–º–µ—Ä –∏–∑–≤–µ—Å—Ç–µ–Ω

‚úÖ **Optimistic retry** (–µ—Å–ª–∏ —Ä–∞–∑–º–µ—Ä –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω):
- –ù–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç upload –ø—Ä–∏ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º —Ä–∞–∑–º–µ—Ä–µ
- Automatic fallback –ø—Ä–∏ "disk full" –æ—à–∏–±–∫–µ
- –î–æ 3 –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–¥ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–º reject

‚úÖ **Graceful degradation**:
- –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–∂–µ –µ—Å–ª–∏ –ø–µ—Ä–≤—ã–π SE –∑–∞–ø–æ–ª–Ω–µ–Ω
- Sequential Fill –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–º SE
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π impact –Ω–∞ user experience

### 4. Fallback –Ω–∞ Admin Module

**–ü–æ—á–µ–º—É –Ω—É–∂–µ–Ω fallback?**

‚úÖ **Resilience**: –°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Redis
‚úÖ **Consistency**: Admin Module ‚Äî single source of truth –¥–ª—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ SE
‚úÖ **Bootstrap**: –ü—Ä–∏ —Å—Ç–∞—Ä—Ç–µ Ingester –º–æ–∂–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –Ω–∞—á–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é

**Fallback –∞–ª–≥–æ—Ä–∏—Ç–º**:

```python
try:
    # Primary: Redis
    se = await select_from_redis(retention_policy)
except RedisError:
    # Fallback: Admin Module HTTP API
    logger.warning("Redis unavailable, falling back to Admin Module")
    se = await admin_client.get_available_storage(retention_policy)
```

**–ü–æ—á–µ–º—É HTTP API, –∞ –Ω–µ –ø—Ä—è–º–æ–µ –æ–±—Ä–∞—â–µ–Ω–∏–µ –∫ PostgreSQL?**

‚úÖ **HTTP API**:
- –°–æ–±–ª—é–¥–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- Admin Module –º–æ–∂–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É
- Authentication —á–µ—Ä–µ–∑ JWT —Ç–æ–∫–µ–Ω—ã
- Audit trail –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤

‚ùå **–ü—Ä—è–º–æ–π –¥–æ—Å—Ç—É–ø –∫ DB**:
- –ù–∞—Ä—É—à–µ–Ω–∏–µ boundary –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏
- –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–º–µ–Ω–∏—Ç—å security policies
- Coupling –º–µ–∂–¥—É —Å—Ö–µ–º–æ–π DB –∏ Ingester

**Admin Module Fallback Endpoint**:

```
GET /api/v1/storage-elements?mode={rw|edit}&available=true&order_by=priority
Authorization: Bearer {service_account_token}

Response:
[
  {
    "id": "se-1",
    "mode": "rw",
    "capacity_percent": 60.0,
    "endpoint": "http://se-1:8010",
    "priority": 1
  },
  ...
]
```

### 5. Alert + Reject –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö SE

**–ü–æ—á–µ–º—É Reject, –∞ –Ω–µ Queue?**

‚úÖ **Reject —Å 503 Service Unavailable**:
- **Honest feedback**: –ö–ª–∏–µ–Ω—Ç –∑–Ω–∞–µ—Ç —á—Ç–æ –∑–∞–ø—Ä–æ—Å –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω
- **Fast fail**: –ù–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è –∏–Ω–¥–∏–∫–∞—Ü–∏—è –ø—Ä–æ–±–ª–µ–º—ã
- **No hidden complexity**: –ù–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —É–ø—Ä–∞–≤–ª—è—Ç—å –æ—á–µ—Ä–µ–¥—å—é
- **Backpressure**: –ö–ª–∏–µ–Ω—Ç –º–æ–∂–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å retry logic

‚ùå **Queue (–æ—Ç–ª–æ–∂–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞)**:
- –£—Å–ª–æ–∂–Ω–µ–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (–Ω—É–∂–Ω–∞ persistent queue)
- –ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∫–ª–∏–µ–Ω—Ç–∞ (–∫–æ–≥–¥–∞ —Ñ–∞–π–ª –±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω?)
- –†–∏—Å–∫ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è queue –ø—Ä–∏ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π unavailability
- –°–ª–æ–∂–Ω–æ—Å—Ç—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏ –≤ queue

**Alert –º–µ—Ö–∞–Ω–∏–∑–º**:

1. **Structured logging**:
   ```python
   logger.critical(
       "No available storage elements",
       extra={
           "alert": "storage_unavailable",
           "severity": "critical",
           "retention_policy": retention_policy
       }
   )
   ```

2. **Prometheus metric**:
   ```python
   storage_unavailable_counter.labels(
       retention_policy=retention_policy
   ).inc()
   ```

3. **AlertManager rule** (–≤ –±—É–¥—É—â–µ–º):
   ```yaml
   - alert: StorageUnavailable
     expr: rate(storage_unavailable_total[5m]) > 0
     for: 1m
     severity: critical
   ```

**–ü–æ—á–µ–º—É –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–µ—Ä—Ç?**

‚úÖ **Critical severity**:
- –ü—Ä—è–º–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã (uploads –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç)
- –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
- –†–∏—Å–∫ –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–∫–∞—Ö –∫–ª–∏–µ–Ω—Ç–∞

---

## –ñ–∏–∑–Ω–µ–Ω–Ω—ã–π —Ü–∏–∫–ª –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: Edit vs RW

### 6. Retention Policy –≤–º–µ—Å—Ç–æ Document Status

**–ü–æ—á–µ–º—É Retention Policy?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **–ë–∏–∑–Ω–µ—Å-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è**: "temporary" / "permanent" –ø–æ–Ω—è—Ç–Ω–µ–µ —á–µ–º "draft" / "final"
- **–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏**: AWS S3 Lifecycle, Google Cloud Storage –∏—Å–ø–æ–ª—å–∑—É—é—Ç retention policies
- **–†–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç—å**: –õ–µ–≥–∫–æ –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø–æ–ª–∏—Ç–∏–∫–∏ (e.g., "archive", "compliance")
- **Separation of concerns**: Retention policy –æ—Ç–¥–µ–ª–µ–Ω–∞ –æ—Ç –±–∏–∑–Ω–µ—Å-—Å—Ç–∞—Ç—É—Å–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã**:
- **Document status (draft/final)**: –°–º–µ—à–∏–≤–∞–µ—Ç –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫—É –∏ storage concerns
- **Workflow states**: –°–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–æ –¥–ª—è simple use cases
- **Implicit (–ø–æ —Ç–∏–ø—É —Ñ–∞–π–ª–∞)**: –ù–µ—Ç –≥–∏–±–∫–æ—Å—Ç–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

**API Design**:

```json
POST /api/v1/upload
{
  "file": "<binary>",
  "retention_policy": "temporary",  // –∏–ª–∏ "permanent"
  "ttl_days": 30,                   // —Ç–æ–ª—å–∫–æ –¥–ª—è temporary
  "metadata": {
    "document_type": "invoice",
    "business_status": "draft"      // –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞
  }
}
```

**–ü–æ—á–µ–º—É TTL —Ç–æ–ª—å–∫–æ –¥–ª—è temporary?**

‚úÖ **TTL –¥–ª—è temporary**:
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –∑–∞–±—ã—Ç—ã—Ö draft'–æ–≤
- –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è Edit SE
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ "–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ" —Ö—Ä–∞–Ω–µ–Ω–∏—è

‚ùå **TTL –¥–ª—è permanent**:
- –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ "permanent" storage
- RW SE –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è long-term retention
- Lifecycle RW ‚Üí RO ‚Üí AR —É–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∞–¥–º–∏–Ω–æ–º, –Ω–µ TTL

**Default TTL = 30 –¥–Ω–µ–π**:

‚úÖ **–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ**:
- –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ä–∞–±–æ—Ç—ã –Ω–∞–¥ –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
- –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –≥–∏–±–∫–æ—Å—Ç—å—é –∏ –∑–∞—â–∏—Ç–æ–π –æ—Ç –º—É—Å–æ—Ä–∞
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–∏—á–Ω—ã–º workflow —Ü–∏–∫–ª–∞–º (sprint, month, etc.)

### 7. Explicit Finalize API

**–ü–æ—á–µ–º—É –æ—Ç–¥–µ–ª—å–Ω—ã–π endpoint –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **Explicit action**: –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è ‚Äî —è–≤–Ω–æ–µ –∏ –æ—Å–æ–∑–Ω–∞–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
- **Audit trail**: –ß—ë—Ç–∫–∞—è –∑–∞–ø–∏—Å—å –∫–æ–≥–¥–∞ –∏ –∫—Ç–æ —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–ª –¥–æ–∫—É–º–µ–Ω—Ç
- **Validation point**: –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–æ–≤–µ—Ä–æ–∫ –ø–µ—Ä–µ–¥ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–µ–π
- **Rollback point**: –ú–æ–∂–Ω–æ –æ—Ç–º–µ–Ω–∏—Ç—å —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—é –¥–æ commit

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è**:
- –í—Ä–µ–º—è-based: –ù–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ, –º–æ–∂–µ—Ç —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–π –¥–æ–∫—É–º–µ–Ω—Ç
- Metadata-based: –°–ª–æ–∂–Ω–æ—Å—Ç—å –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è "readiness" –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏
- –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ explicit control –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

**API Design**:

```json
POST /api/v1/files/{file_id}/finalize
{
  "target_retention_policy": "permanent"
}

Response:
{
  "file_id": "uuid",
  "status": "finalized",
  "transaction_id": "uuid",
  "new_storage_element": "se-rw-1",
  "finalized_at": "2025-12-01T10:00:00Z"
}
```

### 8. Two-Phase Commit –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ–π —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏

**–ü–æ—á–µ–º—É Two-Phase Commit?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **Atomicity**: –õ–∏–±–æ –ø–æ–ª–Ω–∞—è —É—Å–ø–µ—à–Ω–∞—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è, –ª–∏–±–æ rollback
- **Data integrity**: Checksum verification –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç corruption
- **Audit trail**: –í—Å–µ —à–∞–≥–∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ transaction log
- **Recoverability**: –ú–æ–∂–Ω–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø—Ä–µ—Ä–≤–∞–Ω–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã**:
- **Simple Move**: –†–∏—Å–∫ –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ —Å–±–æ–µ –≤–æ –≤—Ä–µ–º—è –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è
- **Copy-Only**: –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ cleanup
- **Async –±–µ–∑ tracking**: –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç–∞—Ç—É—Å –æ–ø–µ—Ä–∞—Ü–∏–∏

**Two-Phase Commit –ø—Ä–æ—Ü–µ—Å—Å**:

```
Phase 1: COPY
‚îú‚îÄ Download file from source Edit SE
‚îú‚îÄ Calculate checksum_source (SHA-256)
‚îú‚îÄ Upload file to target RW SE
‚îú‚îÄ Record transaction: status="copying"
‚îî‚îÄ Update transaction: status="copied", checksum_source

Phase 2: VERIFY & COMMIT
‚îú‚îÄ Request checksum from target RW SE
‚îú‚îÄ Compare checksum_source == checksum_target
‚îú‚îÄ If match:
‚îÇ  ‚îú‚îÄ Update file metadata: storage_element ‚Üí target_se
‚îÇ  ‚îú‚îÄ Update file metadata: retention_policy ‚Üí "permanent"
‚îÇ  ‚îú‚îÄ Update transaction: status="completed"
‚îÇ  ‚îî‚îÄ Schedule cleanup: delete from source Edit SE after 24h
‚îî‚îÄ If mismatch:
   ‚îú‚îÄ Delete file from target RW SE
   ‚îú‚îÄ Update transaction: status="failed"
   ‚îî‚îÄ Raise IntegrityError
```

**–ü–æ—á–µ–º—É SHA-256 –¥–ª—è checksum?**

‚úÖ **SHA-256**:
- Industry standard –¥–ª—è file integrity verification
- Cryptographically secure (collision resistance)
- –î–æ—Å—Ç—É–ø–µ–Ω –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–µ Python (hashlib)
- –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É security –∏ performance

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã**:
- **MD5**: –°—á–∏—Ç–∞–µ—Ç—Å—è weak –¥–ª—è security purposes
- **SHA-512**: Overkill –¥–ª—è file integrity, –º–µ–¥–ª–µ–Ω–Ω–µ–µ
- **CRC32**: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–∞–¥—ë–∂–µ–Ω –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

**–ü–æ—á–µ–º—É 24 —á–∞—Å–∞ safety margin –ø–µ—Ä–µ–¥ delete?**

‚úÖ **24 —á–∞—Å–∞**:
- –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–µ–π
- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å rollback –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
- –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ impact –Ω–∞ capacity Edit SE
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–º SLA (—Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å –¥–ª—è —Ä–µ–∞–∫—Ü–∏–∏)

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã**:
- **–ù–µ–º–µ–¥–ª–µ–Ω–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ**: –†–∏—Å–∫ –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –æ—à–∏–±–∫–µ metadata update
- **7+ –¥–Ω–µ–π**: –ò–∑–±—ã—Ç–æ—á–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, waste of space

### 9. Database Schema –¥–ª—è Transaction Log

**–ü–æ—á–µ–º—É –Ω—É–∂–µ–Ω –æ—Ç–¥–µ–ª—å–Ω—ã–π transaction log?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **Auditability**: –ü–æ–ª–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è –≤—Å–µ—Ö —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–π
- **Debugging**: –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å trace failure –ø—Ä–∏—á–∏–Ω
- **Recovery**: –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
- **Monitoring**: –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–π

**Schema Design**:

```sql
-- Transaction log –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–π
CREATE TABLE file_finalize_transactions (
    transaction_id UUID PRIMARY KEY,
    file_id UUID NOT NULL REFERENCES files(file_id),
    source_se VARCHAR(255) NOT NULL,       -- Edit SE id
    target_se VARCHAR(255) NOT NULL,       -- RW SE id
    status VARCHAR(50) NOT NULL,           -- copying | copied | completed | failed
    checksum_source VARCHAR(64),           -- SHA-256 checksum –æ—Ç source
    checksum_target VARCHAR(64),           -- SHA-256 checksum –æ—Ç target
    error_message TEXT,                    -- –ü—Ä–∏ status=failed
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    completed_at TIMESTAMP
);

CREATE INDEX idx_file_finalize_tx_file_id ON file_finalize_transactions(file_id);
CREATE INDEX idx_file_finalize_tx_status ON file_finalize_transactions(status);
CREATE INDEX idx_file_finalize_tx_created ON file_finalize_transactions(created_at);

-- Cleanup queue –¥–ª—è –æ—Ç–ª–æ–∂–µ–Ω–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
CREATE TABLE file_cleanup_queue (
    id SERIAL PRIMARY KEY,
    file_id UUID NOT NULL,
    storage_element_id VARCHAR(255) NOT NULL,
    scheduled_at TIMESTAMP NOT NULL,       -- –ö–æ–≥–¥–∞ —É–¥–∞–ª—è—Ç—å (created + 24h)
    processed_at TIMESTAMP,                -- –ö–æ–≥–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ
    error_message TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_cleanup_queue_scheduled ON file_cleanup_queue(scheduled_at)
WHERE processed_at IS NULL;
```

**–ü–æ—á–µ–º—É –æ—Ç–¥–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ cleanup_queue?**

‚úÖ **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**:
- **Decoupling**: Cleanup –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç finalize transaction
- **Retry logic**: –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å failed cleanup
- **Batch processing**: GC job –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç cleanup –±–∞—Ç—á–∞–º–∏
- **Monitoring**: –û—Ç–¥–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è cleanup –æ–ø–µ—Ä–∞—Ü–∏–π

### 10. Garbage Collection Background Job

**–ü–æ—á–µ–º—É background job, –∞ –Ω–µ event-driven cleanup?**

‚úÖ **Background job (periodic)**:
- **Simplicity**: –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –±–µ–∑ event bus
- **Batch efficiency**: –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ñ–∞–π–ª–æ–≤ –∑–∞ —Ä–∞–∑
- **Resource control**: –ú–æ–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å CPU/IO usage
- **Predictability**: –ß—ë—Ç–∫–æ–µ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è –æ–ø–µ—Ä–∞—Ü–∏–π

‚ùå **Event-driven (immediate)**:
- –°–ª–æ–∂–Ω–æ—Å—Ç—å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏–∏ –º–µ–∂–¥—É —Å–µ—Ä–≤–∏—Å–∞–º–∏
- –í–æ–∑–º–æ–∂–Ω—ã–µ race conditions
- –ù–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ Storage Elements

**GC Job —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏**:

| –°—Ç—Ä–∞—Ç–µ–≥–∏—è | –û–ø–∏—Å–∞–Ω–∏–µ | Frequency | –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ |
|-----------|----------|-----------|-------------|
| **TTL-based cleanup** | –£–¥–∞–ª–µ–Ω–∏–µ temporary —Ñ–∞–π–ª–æ–≤ —Å –∏—Å—Ç–µ–∫—à–∏–º TTL | Every 6h | –†–µ–≥—É–ª—è—Ä–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ forgotten drafts |
| **Finalized files cleanup** | –£–¥–∞–ª–µ–Ω–∏–µ –∏–∑ Edit SE –ø–æ—Å–ª–µ finalize (safety margin 24h) | Every 6h | –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ Two-Phase Commit |
| **Orphaned files cleanup** | –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –±–µ–∑ –∑–∞–ø–∏—Å–µ–π –≤ DB (age > 7 days) | Every 6h | –ó–∞—â–∏—Ç–∞ –æ—Ç data inconsistency |

**–ü–æ—á–µ–º—É 6 —á–∞—Å–æ–≤ –¥–ª—è run interval?**

‚úÖ **6 —á–∞—Å–æ–≤**:
- –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —á–∞—Å—Ç–æ–µ –¥–ª—è —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏
- –ù–∏–∑–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞ –Ω–∞ —Å–∏—Å—Ç–µ–º—É (4 runs/day)
- –ü—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
- –ë–∞–ª–∞–Ω—Å –º–µ–∂–¥—É –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å—é –∏ resource usage

‚ùå **–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã**:
- **1 —á–∞—Å**: –ò–∑–±—ã—Ç–æ—á–Ω–∞—è —á–∞—Å—Ç–æ—Ç–∞, –ª–∏—à–Ω—è—è –Ω–∞–≥—Ä—É–∑–∫–∞
- **24 —á–∞—Å–∞**: –°–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è, —Ä–∏—Å–∫ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è Edit SE

**–ü–æ—á–µ–º—É 7 –¥–Ω–µ–π –¥–ª—è orphaned files?**

‚úÖ **7 –¥–Ω–µ–π safety margin**:
- –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è data inconsistency
- –ó–∞—â–∏—Ç–∞ –æ—Ç —Å–ª—É—á–∞–π–Ω–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è "–∑–∞–±—ã—Ç—ã—Ö" —Ñ–∞–π–ª–æ–≤
- –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ retention policies –¥–ª—è temporary storage

**GC Job implementation details**:

```python
# admin-module/app/services/garbage_collector.py

class GarbageCollector:
    async def start(self):
        """–ó–∞–ø—É—Å–∫ periodic GC job"""
        while True:
            await self._run_cleanup_cycle()
            await asyncio.sleep(6 * 3600)  # 6 hours

    async def _run_cleanup_cycle(self):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ—á–∏—Å—Ç–∫–∏"""
        # 1. TTL-based cleanup
        ttl_cleaned = await self._cleanup_expired_ttl()

        # 2. Finalized files cleanup
        finalized_cleaned = await self._cleanup_finalized_files()

        # 3. Orphaned files cleanup
        orphaned_cleaned = await self._cleanup_orphaned_files()

        # Metrics
        gc_cleanup_total.labels(type="ttl").inc(ttl_cleaned)
        gc_cleanup_total.labels(type="finalized").inc(finalized_cleaned)
        gc_cleanup_total.labels(type="orphaned").inc(orphaned_cleaned)
```

---

## Comprehensive Monitoring & Alerting

### 1. Enhanced Prometheus Metrics

**Capacity Metrics** (real-time monitoring):

```python
# storage-element/app/core/metrics.py

from prometheus_client import Gauge, Counter, Histogram

# Capacity –≤ bytes (–¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–∞ –±–æ–ª—å—à–∏—Ö SE)
storage_capacity_total_bytes = Gauge(
    "storage_capacity_total_bytes",
    "Total storage capacity in bytes",
    ["se_id", "mode"]
)

storage_capacity_used_bytes = Gauge(
    "storage_capacity_used_bytes",
    "Used storage capacity in bytes",
    ["se_id", "mode"]
)

storage_capacity_free_bytes = Gauge(
    "storage_capacity_free_bytes",
    "Free storage capacity in bytes",
    ["se_id", "mode"]
)

# Capacity status (0=ok, 1=warning, 2=critical, 3=full)
storage_capacity_status = Gauge(
    "storage_capacity_status",
    "Current capacity status",
    ["se_id", "mode"]
)

# Capacity forecast (predictive analytics)
storage_capacity_forecast_days = Gauge(
    "storage_capacity_forecast_days",
    "Forecast: days until threshold at current fill rate",
    ["se_id", "threshold"]  # threshold: warning|critical|full
)

# Upload rejections
storage_upload_rejected_total = Counter(
    "storage_upload_rejected_total",
    "Total uploads rejected due to capacity",
    ["se_id", "reason"]  # reason: full|no_space_for_file
)

# Automatic SE switching
storage_element_switch_total = Counter(
    "storage_element_switch_total",
    "Total automatic SE switches",
    ["from_se", "to_se", "reason"]  # reason: full|insufficient_space
)

# Selection performance
storage_selection_duration_seconds = Histogram(
    "storage_selection_duration_seconds",
    "Duration of SE selection",
    ["retention_policy"]
)

storage_selection_total = Counter(
    "storage_selection_total",
    "Total SE selections",
    ["retention_policy", "status"]  # status: success|fallback|failed
)
```

### 2. Capacity Forecasting

**Predictive Analytics –¥–ª—è proactive management**:

```python
# storage-element/app/services/capacity_forecaster.py

from datetime import datetime, timedelta
from typing import Optional

class CapacityForecaster:
    """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è Storage Element."""

    def __init__(self, redis_client):
        self.redis = redis_client
        self.history_key_prefix = "storage:history:"
        self.history_retention_days = 30

    async def record_capacity_snapshot(self, se_id: str, used_bytes: int):
        """–ó–∞–ø–∏—Å–∞—Ç—å capacity snapshot –¥–ª—è forecasting."""
        timestamp = int(datetime.utcnow().timestamp())

        # Redis time series (sorted set)
        await self.redis.zadd(
            f"{self.history_key_prefix}{se_id}",
            {f"{timestamp}:{used_bytes}": timestamp}
        )

        # Cleanup —Å—Ç–∞—Ä—ã—Ö –∑–∞–ø–∏—Å–µ–π (> 30 –¥–Ω–µ–π)
        cutoff = timestamp - (self.history_retention_days * 86400)
        await self.redis.zremrangebyscore(
            f"{self.history_key_prefix}{se_id}",
            0,
            cutoff
        )

    async def forecast_days_until_full(
        self,
        se_id: str,
        total_capacity: int,
        threshold_bytes: int
    ) -> Optional[float]:
        """
        –ü—Ä–æ–≥–Ω–æ–∑: –∑–∞ —Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π SE –∑–∞–ø–æ–ª–Ω–∏—Ç—Å—è –¥–æ threshold.

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö
        """
        # –ü–æ–ª—É—á–∏—Ç—å historical data (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π)
        history_key = f"{self.history_key_prefix}{se_id}"
        now = int(datetime.utcnow().timestamp())
        week_ago = now - (7 * 86400)

        history = await self.redis.zrangebyscore(
            history_key,
            week_ago,
            now,
            withscores=True
        )

        if len(history) < 2:
            return None  # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö

        # Linear regression –¥–ª—è rate of fill
        data_points = []
        for entry, timestamp in history:
            _, used_bytes_str = entry.split(":")
            data_points.append({
                "timestamp": timestamp,
                "used_bytes": int(used_bytes_str)
            })

        first = data_points[0]
        last = data_points[-1]

        time_delta_seconds = last["timestamp"] - first["timestamp"]
        bytes_delta = last["used_bytes"] - first["used_bytes"]

        if time_delta_seconds == 0 or bytes_delta <= 0:
            return None  # –ù–µ—Ç —Ä–æ—Å—Ç–∞

        # Rate of fill (bytes/second)
        fill_rate = bytes_delta / time_delta_seconds

        # Remaining bytes –¥–æ threshold
        remaining_bytes = threshold_bytes - last["used_bytes"]

        if remaining_bytes <= 0:
            return 0  # –£–∂–µ –∑–∞ threshold

        # Days until threshold
        seconds_until = remaining_bytes / fill_rate
        days_until = seconds_until / 86400

        return days_until
```

**–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ HealthReporter**:

```python
async def _report_status(self):
    """Report —Å forecasting."""
    # ... existing capacity calculation

    # Record snapshot –¥–ª—è forecasting
    await capacity_forecaster.record_capacity_snapshot(
        self.se_id,
        storage_stats["used"]
    )

    # Forecast –¥–ª—è –∫–∞–∂–¥–æ–≥–æ threshold
    thresholds = calculate_adaptive_threshold(
        storage_stats["total"],
        settings.storage_mode
    )

    for threshold_name in ["warning", "critical", "full"]:
        threshold_bytes = (
            storage_stats["total"] -
            int(thresholds[f"{threshold_name}_free_gb"] * 1024**3)
        )

        forecast_days = await capacity_forecaster.forecast_days_until_full(
            self.se_id,
            storage_stats["total"],
            threshold_bytes
        )

        if forecast_days is not None:
            # Update Prometheus metric
            storage_capacity_forecast_days.labels(
                se_id=self.se_id,
                threshold=threshold_name
            ).set(forecast_days)

            # Log –µ—Å–ª–∏ forecast < 30 –¥–Ω–µ–π
            if forecast_days < 30:
                logger.warning(
                    f"SE {self.se_id} forecasted to reach {threshold_name} "
                    f"in {forecast_days:.1f} days",
                    extra={
                        "se_id": self.se_id,
                        "threshold": threshold_name,
                        "forecast_days": forecast_days
                    }
                )
```

### 3. Prometheus AlertManager Rules

```yaml
# monitoring/prometheus/alerts/storage_capacity.yml

groups:
  - name: storage_capacity
    interval: 30s
    rules:
      # Multi-level capacity alerts
      - alert: StorageCapacityWarning
        expr: storage_capacity_status{status="warning"} == 1
        for: 5m
        labels:
          severity: warning
          component: storage
        annotations:
          summary: "Storage {{ $labels.se_id }} capacity warning"
          description: |
            Storage Element {{ $labels.se_id }} has reached warning threshold.
            Free space: {{ query "storage_capacity_free_bytes{se_id='$labels.se_id'} / 1024^3" | first | value | humanize }}GB
            Forecast (full): {{ query "storage_capacity_forecast_days{se_id='$labels.se_id',threshold='full'}" | first | value | humanize }} days

      - alert: StorageCapacityCritical
        expr: storage_capacity_status{status="critical"} == 2
        for: 2m
        labels:
          severity: critical
          component: storage
        annotations:
          summary: "Storage {{ $labels.se_id }} capacity CRITICAL"
          description: |
            URGENT: Storage Element {{ $labels.se_id }} critically low on space.
            Free space: {{ query "storage_capacity_free_bytes{se_id='$labels.se_id'} / 1024^3" | first | value | humanize }}GB
            Forecast (full): {{ query "storage_capacity_forecast_days{se_id='$labels.se_id',threshold='full'}" | first | value | humanize }} days
            ACTION REQUIRED: Add capacity immediately.

      - alert: StorageCapacityFull
        expr: storage_capacity_status{status="full"} == 3
        for: 1m
        labels:
          severity: page
          component: storage
        annotations:
          summary: "Storage {{ $labels.se_id }} is FULL"
          description: |
            CRITICAL: Storage Element {{ $labels.se_id }} is full and rejecting writes.
            System automatically switching to next SE.
            IMMEDIATE ACTION: Expand capacity or migrate data.

      # Predictive alert (7+ days forecast)
      - alert: StorageCapacityPredictiveFull
        expr: storage_capacity_forecast_days{threshold="full"} < 7 and storage_capacity_forecast_days{threshold="full"} > 0
        for: 1h
        labels:
          severity: warning
          component: storage
        annotations:
          summary: "Storage {{ $labels.se_id }} will be full in < 7 days"
          description: |
            Storage Element {{ $labels.se_id }} forecasted to reach capacity in {{ $value | humanize }} days.
            Current fill rate indicates proactive action needed.
            Consider expanding capacity or implementing lifecycle policies.

      # Upload rejection alert
      - alert: StorageUploadRejections
        expr: rate(storage_upload_rejected_total[5m]) > 0.1
        for: 2m
        labels:
          severity: critical
          component: storage
        annotations:
          summary: "High upload rejection rate on {{ $labels.se_id }}"
          description: |
            Storage Element {{ $labels.se_id }} rejecting uploads.
            Rejection rate: {{ $value | humanizePercentage }}
            May indicate insufficient capacity across all SE.

      # Automatic SE switching (–º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –ø—Ä–æ–±–ª–µ–º—ã)
      - alert: FrequentStorageSwitching
        expr: rate(storage_element_switch_total[10m]) > 0.5
        for: 5m
        labels:
          severity: warning
          component: storage
        annotations:
          summary: "Frequent automatic SE switching detected"
          description: |
            System frequently switching between Storage Elements.
            Switch rate: {{ $value }} switches/second
            This may indicate capacity issues or misconfiguration.
```

### 4. Structured Logging

**Capacity Status Logging**:

```python
# storage-element/app/services/health_reporter.py

async def _report_status(self):
    """Report —Å comprehensive logging."""
    storage_stats = await self._get_storage_stats()
    thresholds = calculate_adaptive_threshold(
        storage_stats["total"],
        settings.storage_mode
    )
    status = get_capacity_status(
        storage_stats["used"],
        storage_stats["total"],
        thresholds
    )

    # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª–æ–≥
    log_data = {
        "event": "storage_capacity_status",
        "se_id": self.se_id,
        "mode": settings.storage_mode,
        "capacity": {
            "total_gb": storage_stats["total"] / (1024**3),
            "used_gb": storage_stats["used"] / (1024**3),
            "free_gb": (storage_stats["total"] - storage_stats["used"]) / (1024**3),
            "percent": storage_stats["percent"]
        },
        "status": status.value,
        "thresholds": {
            "warning_pct": thresholds["warning_threshold"],
            "critical_pct": thresholds["critical_threshold"],
            "full_pct": thresholds["full_threshold"],
            "warning_free_gb": thresholds["warning_free_gb"],
            "critical_free_gb": thresholds["critical_free_gb"],
            "full_free_gb": thresholds["full_free_gb"]
        }
    }

    # Log level –Ω–∞ –æ—Å–Ω–æ–≤–µ status
    if status == CapacityStatus.FULL:
        logger.critical("Storage capacity FULL", extra=log_data)
    elif status == CapacityStatus.CRITICAL:
        logger.error("Storage capacity CRITICAL", extra=log_data)
    elif status == CapacityStatus.WARNING:
        logger.warning("Storage capacity WARNING", extra=log_data)
    else:
        logger.info("Storage capacity OK", extra=log_data)
```

**Upload Rejection Logging**:

```python
# ingester-module/app/api/v1/endpoints/upload.py

if not target_se:
    logger.critical(
        "No available storage for upload",
        extra={
            "event": "storage_unavailable",
            "retention_policy": retention_policy,
            "file_size": file_size,
            "available_se_count": await storage_selector.count_available_se(retention_policy),
            "alert": "critical"
        }
    )

    # Prometheus metric
    storage_unavailable_counter.labels(
        retention_policy=retention_policy
    ).inc()

    raise HTTPException(503, "No available storage")
```

### 5. Admin UI Visualization

**Dashboard Components**:

```typescript
// admin-ui/src/app/components/storage-capacity-dashboard/

interface StorageElementStatus {
  id: string;
  mode: 'rw' | 'ro' | 'ar' | 'edit';
  capacityTotal: number;  // bytes
  capacityUsed: number;
  capacityFree: number;
  capacityPercent: number;
  status: 'ok' | 'warning' | 'critical' | 'full';
  thresholds: {
    warning: { percent: number; freeGb: number };
    critical: { percent: number; freeGb: number };
    full: { percent: number; freeGb: number };
  };
  forecast: {
    warningDays: number | null;
    criticalDays: number | null;
    fullDays: number | null;
  };
}
```

**Capacity Gauge Component**:

```html
<div class="capacity-gauge" [ngClass]="status">
  <!-- Progress bar -->
  <div class="gauge-fill" [style.width.%]="capacityPercent"></div>

  <!-- Threshold markers -->
  <div class="threshold-marker warning" [style.left.%]="thresholds.warning.percent"></div>
  <div class="threshold-marker critical" [style.left.%]="thresholds.critical.percent"></div>
  <div class="threshold-marker full" [style.left.%]="thresholds.full.percent"></div>

  <!-- Label -->
  <div class="gauge-label">
    {{ capacityUsed | fileSize }} / {{ capacityTotal | fileSize }}
    ({{ capacityPercent | number:'1.1-1' }}%)
  </div>
</div>

<!-- Forecast widget -->
<div class="forecast-widget" *ngIf="forecast.fullDays !== null">
  <mat-icon [ngClass]="getForecastSeverity(forecast.fullDays)">
    schedule
  </mat-icon>
  <span>
    Full in {{ forecast.fullDays | number:'1.0-0' }} days
  </span>
</div>

<!-- Capacity trend chart -->
<canvas baseChart
  [datasets]="capacityChartData"
  [labels]="capacityChartLabels"
  [options]="capacityChartOptions"
  [type]="'line'">
</canvas>
```

**Color Coding (CSS)**:

```css
.capacity-gauge.ok {
  border-color: #4caf50;  /* Green */
}

.capacity-gauge.warning {
  border-color: #ff9800;  /* Orange */
}

.capacity-gauge.critical {
  border-color: #f44336;  /* Red */
}

.capacity-gauge.full {
  border-color: #9c27b0;  /* Purple */
}

.forecast-widget .mat-icon.safe {
  color: #4caf50;  /* > 30 days */
}

.forecast-widget .mat-icon.warning {
  color: #ff9800;  /* 7-30 days */
}

.forecast-widget .mat-icon.urgent {
  color: #f44336;  /* < 7 days */
}
```

---

## –ê–∫—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∏—Ç–æ–≥–æ–≤–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è

### –ö–ª—é—á–µ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –æ—Ç –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–ª–∞–Ω–∞

| –ê—Å–ø–µ–∫—Ç | –ë—ã–ª–æ | –°—Ç–∞–ª–æ |
|--------|------|-------|
| **Capacity Threshold** | –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π 95% | Adaptive: MAX(2%, 50GB free) –¥–ª—è RW, MAX(1%, 30GB) –¥–ª—è Edit |
| **Alerting** | –ë–∏–Ω–∞—Ä–Ω—ã–π (ok/reject) | Multi-level (ok ‚Üí warning ‚Üí critical ‚Üí full) |
| **File Size Handling** | –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–ª—Å—è | Pre-flight check (Content-Length) + optimistic retry |
| **Monitoring** | Basic capacity metrics | Comprehensive: bytes metrics + status + forecast + rejections |
| **Forecasting** | –û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–æ | Predictive analytics —Å 7-30 –¥–Ω–µ–≤–Ω—ã–º–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞–º–∏ |
| **Logging** | Simple logs | Structured JSON logs —Å event types –∏ severity |
| **Admin UI** | –û—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–æ | Real-time dashboard —Å gauges, trends, forecast widgets |

### –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∞–∫—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏

‚úÖ **Efficiency**: 98%+ utilization –Ω–∞ –±–æ–ª—å—à–∏—Ö SE –≤–º–µ—Å—Ç–æ 95%
‚úÖ **Safety**: –ó–∞—â–∏—Ç–∞ –º–∞–ª—ã—Ö SE (–º–∏–Ω–∏–º—É–º 50GB/30GB free)
‚úÖ **Proactive**: Multi-level alerting –¥–∞—ë—Ç –≤—Ä–µ–º—è –¥–ª—è —Ä–µ–∞–∫—Ü–∏–∏ (warning ‚Üí critical ‚Üí full)
‚úÖ **Resilience**: Intelligent fallback –ø—Ä–∏ insufficient space (–¥–æ 3 retry)
‚úÖ **Visibility**: Comprehensive monitoring –Ω–∞ –≤—Å–µ—Ö —É—Ä–æ–≤–Ω—è—Ö (metrics + logs + UI + forecast)
‚úÖ **Predictive**: Forecasting –∑–∞ 7-30 –¥–Ω–µ–π –¥–ª—è proactive capacity management
‚úÖ **Scalable**: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∞–¥–∞–ø—Ç–∞—Ü–∏—è –∫ –ª—é–±–æ–º—É —Ä–∞–∑–º–µ—Ä—É SE –±–µ–∑ configuration

---

## Implementation Tasks

### Phase 1: Redis Storage Registry (Sprint 14)

#### Task 1.1: Redis Schema & Health Reporting

**–¶–µ–ª—å**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Redis registry –¥–ª—è Storage Elements —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º health reporting.

**–ú–æ–¥—É–ª–∏**: `storage-element`, `admin-module`

**Subtasks**:

1. **–û–±–Ω–æ–≤–∏—Ç—å Storage Element config**:
   ```python
   # storage-element/app/core/config.py

   class StorageElementSettings(BaseSettings):
       # ... existing fields

       # New fields –¥–ª—è health reporting
       storage_element_id: str = Field(..., env="STORAGE_ELEMENT_ID")
       priority: int = Field(default=100, env="STORAGE_PRIORITY")
       external_endpoint: str = Field(..., env="STORAGE_EXTERNAL_ENDPOINT")
       health_report_interval: int = Field(default=30, env="HEALTH_REPORT_INTERVAL")
   ```

2. **–°–æ–∑–¥–∞—Ç—å HealthReporter service**:
   ```bash
   storage-element/app/services/health_reporter.py
   ```
   - Periodic background task (async)
   - –ü—É–±–ª–∏–∫–∞—Ü–∏—è –≤ Redis: `storage:elements:{se_id}` –∏ `storage:{mode}:by_priority`
   - –†–∞—Å—á—ë—Ç capacity statistics (statvfs –¥–ª—è local, boto3 –¥–ª—è S3)
   - Error handling —Å retry logic

3. **–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å HealthReporter –≤ main.py**:
   ```python
   # storage-element/app/main.py

   @app.on_event("startup")
   async def startup_event():
       # ... existing

       # Start health reporting
       health_reporter = HealthReporter(redis_client)
       asyncio.create_task(health_reporter.start_reporting())
   ```

4. **Unit —Ç–µ—Å—Ç—ã –¥–ª—è HealthReporter**:
   ```bash
   storage-element/tests/unit/test_health_reporter.py
   ```
   - Mock Redis operations
   - Test capacity calculation
   - Test error recovery

**Acceptance Criteria**:
- [x] Storage Element –ø—É–±–ª–∏–∫—É–µ—Ç —Å—Ç–∞—Ç—É—Å –≤ Redis –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
- [x] Redis —Å–æ–¥–µ—Ä–∂–∏—Ç –∞–∫—Ç—É–∞–ª—å–Ω—É—é capacity –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
- [x] Sorted Set `storage:rw:by_priority` –∏ `storage:edit:by_priority` –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è
- [x] Prometheus metrics –¥–ª—è capacity monitoring (Sprint 14 addition)
- [ ] Unit —Ç–µ—Å—Ç—ã –ø–æ–∫—Ä—ã–≤–∞—é—Ç ‚â•90% –∫–æ–¥–∞ (TODO: –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã)

**Estimated Effort**: 6 hours

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã**:
- `storage-element/app/core/config.py` - –î–æ–±–∞–≤–ª–µ–Ω—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: element_id, priority, external_endpoint, health_report_interval, health_report_ttl
- `storage-element/app/core/capacity_calculator.py` - Adaptive threshold calculator —Å CapacityStatus enum
- `storage-element/app/core/capacity_metrics.py` - **NEW** Prometheus metrics: capacity gauges, status gauges, thresholds, file operations, Redis publish metrics
- `storage-element/app/services/health_reporter.py` - **NEW** HealthReporter service —Å periodic background task
- `storage-element/app/main.py` - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è HealthReporter –≤ lifespan

---

#### Task 1.2: Storage Selector –≤ Ingester Module

**–¶–µ–ª—å**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å Sequential Fill –∞–ª–≥–æ—Ä–∏—Ç–º –≤—ã–±–æ—Ä–∞ Storage Element.

**–ú–æ–¥—É–ª–∏**: `ingester-module`

**Subtasks**:

1. **–°–æ–∑–¥–∞—Ç—å StorageSelector service**:
   ```bash
   ingester-module/app/services/storage_selector.py
   ```
   - –ú–µ—Ç–æ–¥ `select_storage_element(retention_policy)`
   - Sequential Fill —á–µ—Ä–µ–∑ Redis Sorted Set
   - Capacity threshold checks (95% RW, 90% Edit)
   - Fallback –Ω–∞ Admin Module HTTP API

2. **–°–æ–∑–¥–∞—Ç—å Admin Module fallback client**:
   ```bash
   ingester-module/app/clients/admin_client.py
   ```
   - HTTP client –¥–ª—è `/api/v1/storage-elements`
   - Authentication —á–µ—Ä–µ–∑ service account JWT
   - Error handling –∏ retry logic

3. **–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å StorageSelector –≤ upload endpoint**:
   ```python
   # ingester-module/app/api/v1/endpoints/upload.py

   @router.post("/upload")
   async def upload_file(
       file: UploadFile,
       retention_policy: RetentionPolicy = RetentionPolicy.PERMANENT,
       storage_selector: StorageSelector = Depends(get_storage_selector)
   ):
       target_se = await storage_selector.select_storage_element(retention_policy)

       if not target_se:
           # Alert + Reject
           raise HTTPException(503, "No available storage")

       # ... continue upload
   ```

4. **Unit –∏ integration —Ç–µ—Å—Ç—ã**:
   ```bash
   ingester-module/tests/unit/test_storage_selector.py
   ingester-module/tests/integration/test_upload_with_selection.py
   ```
   - Mock Redis responses
   - Test fallback –∫ Admin Module
   - Test capacity threshold logic
   - Test 503 error –ø—Ä–∏ unavailability

**Acceptance Criteria**:
- [x] Ingester –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤—ã–±–∏—Ä–∞–µ—Ç SE –ø–æ Sequential Fill –∞–ª–≥–æ—Ä–∏—Ç–º—É
- [x] Fallback –Ω–∞ Admin Module —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Redis (—á–µ—Ä–µ–∑ admin_client.py)
- [x] 503 error –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö SE (NoAvailableStorageException)
- [x] Prometheus metrics –¥–ª—è selection failures (—Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –±–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏)
- [x] Upload endpoint –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω —Å StorageSelector
- [ ] Unit —Ç–µ—Å—Ç—ã –ø–æ–∫—Ä—ã–≤–∞—é—Ç ‚â•90% –∫–æ–¥–∞ (TODO: –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã)

**Estimated Effort**: 8 hours

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã**:
- `ingester-module/app/services/storage_selector.py` - **NEW** StorageSelector —Å Sequential Fill, Redis + fallback –Ω–∞ Admin Module + fallback –Ω–∞ local config
- `ingester-module/app/clients/admin_client.py` - **NEW** HTTP client –¥–ª—è Admin Module fallback API
- `ingester-module/app/services/upload_service.py` - –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è StorageSelector, dynamic SE endpoint selection, HTTP client caching
- `ingester-module/app/core/exceptions.py` - –î–æ–±–∞–≤–ª–µ–Ω NoAvailableStorageException
- `ingester-module/app/core/redis.py` - Redis async client –¥–ª—è Ingester
- `ingester-module/app/main.py` - –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis –∏ StorageSelector –≤ lifespan

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**:
- –ú–∞–ø–ø–∏–Ω–≥ storage_mode ‚Üí retention_policy: edit=TEMPORARY, rw=PERMANENT
- HTTP client –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è multiple SE endpoints
- Graceful degradation: Redis ‚Üí Admin Module ‚Üí Local config

---

#### Task 1.3: Admin Module Storage Elements API

**–¶–µ–ª—å**: –°–æ–∑–¥–∞—Ç—å REST API –¥–ª—è fallback –∑–∞–ø—Ä–æ—Å–æ–≤ –æ—Ç Ingester.

**–ú–æ–¥—É–ª–∏**: `admin-module`

**Subtasks**:

1. **–°–æ–∑–¥–∞—Ç—å endpoint `/api/v1/storage-elements`**:
   ```bash
   admin-module/app/api/v1/endpoints/storage_elements.py
   ```
   - GET endpoint —Å query parameters: `mode`, `available`, `order_by`
   - –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ capacity threshold
   - –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ priority
   - Authentication —á–µ—Ä–µ–∑ JWT

2. **–°–æ–∑–¥–∞—Ç—å StorageElementService**:
   ```bash
   admin-module/app/services/storage_element_service.py
   ```
   - –ü–æ–ª—É—á–µ–Ω–∏–µ SE –∏–∑ Redis
   - Fallback –Ω–∞ database –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Redis
   - –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ filters –∏ sorting

3. **Integration —Ç–µ—Å—Ç—ã**:
   ```bash
   admin-module/tests/integration/test_storage_elements_api.py
   ```
   - Test GET endpoint
   - Test authentication
   - Test query parameters filtering

**Acceptance Criteria**:
- [x] GET `/api/internal/storage-elements/available` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ SE
- [x] Endpoint —Ç—Ä–µ–±—É–µ—Ç JWT authentication (service account)
- [x] API —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ mode –∏ capacity_status
- [ ] Integration —Ç–µ—Å—Ç—ã –ø–æ–∫—Ä—ã–≤–∞—é—Ç –≤—Å–µ query parameters (TODO: –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã)
- [x] API –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤ Swagger UI (internal tag)

**Estimated Effort**: 4 hours

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã**:
- `admin-module/app/api/v1/endpoints/internal.py` - **NEW** Internal endpoint –¥–ª—è fallback –∑–∞–ø—Ä–æ—Å–æ–≤ –æ—Ç Ingester
- `admin-module/app/api/v1/router.py` - –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è internal router
- `admin-module/app/models/storage_element.py` - SQLAlchemy –º–æ–¥–µ–ª—å (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é)

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**:
- Endpoint: `GET /api/v1/internal/storage-elements/available?mode={rw|edit}`
- –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π API (internal tag –≤ Swagger), –Ω–µ –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ–Ω –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: mode, capacity_status != full
- –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: –ø–æ priority (ascending)

---

## Implementation Status Summary - Phase 1 (Sprint 14) ‚úÖ

| Task | Status | Notes |
|------|--------|-------|
| **Task 1.1**: Redis Schema & Health Reporting | ‚úÖ DONE | HealthReporter + Prometheus metrics |
| **Task 1.2**: Storage Selector –≤ Ingester | ‚úÖ DONE | Sequential Fill + triple fallback |
| **Task 1.3**: Admin Module Internal API | ‚úÖ DONE | Fallback endpoint |
| **Unit Tests** | ‚è≥ TODO | –¢—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã |

---

### Phase 2: Retention Policy & Lifecycle (Sprint 15) - ‚úÖ IMPLEMENTED

**Status**: COMPLETED (2024-12-02)

**Summary**:
- Database migrations applied successfully
- Upload API supports retention_policy and ttl_days parameters
- Finalize API endpoint implemented with Two-Phase Commit
- Models created: File, FileFinalizeTransaction, FileCleanupQueue
- Integration tests pending (Sprint 16)

#### Task 2.1: Database Schema –¥–ª—è Retention Policy

**–¶–µ–ª—å**: –û–±–Ω–æ–≤–∏—Ç—å database schema –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ retention policies –∏ transaction logging.

**–ú–æ–¥—É–ª–∏**: `admin-module`, `storage-element`, `ingester-module`, `query-module`

**Subtasks**:

1. **–°–æ–∑–¥–∞—Ç—å Alembic migration –¥–ª—è files table**:
   ```bash
   admin-module/alembic/versions/xxx_add_retention_policy.py
   ```
   ```sql
   ALTER TABLE files
   ADD COLUMN retention_policy VARCHAR(20) NOT NULL DEFAULT 'permanent',
   ADD COLUMN ttl_expires_at TIMESTAMP,
   ADD COLUMN finalized_at TIMESTAMP;

   CREATE INDEX idx_files_retention_policy ON files(retention_policy);
   CREATE INDEX idx_files_ttl_expires ON files(ttl_expires_at)
   WHERE retention_policy = 'temporary';
   ```

2. **–°–æ–∑–¥–∞—Ç—å file_finalize_transactions table**:
   ```sql
   CREATE TABLE file_finalize_transactions (
       transaction_id UUID PRIMARY KEY,
       file_id UUID NOT NULL REFERENCES files(file_id),
       source_se VARCHAR(255) NOT NULL,
       target_se VARCHAR(255) NOT NULL,
       status VARCHAR(50) NOT NULL,
       checksum_source VARCHAR(64),
       checksum_target VARCHAR(64),
       error_message TEXT,
       created_at TIMESTAMP NOT NULL DEFAULT NOW(),
       updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
       completed_at TIMESTAMP
   );
   ```

3. **–°–æ–∑–¥–∞—Ç—å file_cleanup_queue table**:
   ```sql
   CREATE TABLE file_cleanup_queue (
       id SERIAL PRIMARY KEY,
       file_id UUID NOT NULL,
       storage_element_id VARCHAR(255) NOT NULL,
       scheduled_at TIMESTAMP NOT NULL,
       processed_at TIMESTAMP,
       error_message TEXT,
       created_at TIMESTAMP NOT NULL DEFAULT NOW()
   );
   ```

4. **–û–±–Ω–æ–≤–∏—Ç—å SQLAlchemy models**:
   ```bash
   admin-module/app/models/file.py
   admin-module/app/models/finalize_transaction.py
   admin-module/app/models/cleanup_queue.py
   ```

5. **–¢–µ—Å—Ç–æ–≤–∞—è –º–∏–≥—Ä–∞—Ü–∏—è –Ω–∞ dev environment**:
   ```bash
   docker-compose exec admin-module alembic upgrade head
   ```

**Acceptance Criteria**:
- [x] Alembic migrations –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫
- [x] –í—Å–µ indexes —Å–æ–∑–¥–∞–Ω—ã –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
- [x] SQLAlchemy models —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å schema
- [x] Rollback –º–∏–≥—Ä–∞—Ü–∏–π —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ

**Estimated Effort**: 4 hours

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã** (Sprint 15):
- `admin-module/alembic/versions/20251201_0002_add_retention_policy_and_lifecycle.py` - **NEW** –ú–∏–≥—Ä–∞—Ü–∏—è –¥–ª—è files, file_finalize_transactions, file_cleanup_queue
- `admin-module/app/models/file.py` - **NEW** File model —Å retention_policy, ttl_expires_at, user_metadata
- `admin-module/app/models/finalize_transaction.py` - **NEW** FileFinalizeTransaction model –¥–ª—è Two-Phase Commit
- `admin-module/app/models/cleanup_queue.py` - **NEW** FileCleanupQueue model –¥–ª—è GC
- `admin-module/app/models/__init__.py` - –û–±–Ω–æ–≤–ª—ë–Ω —Å –∏–º–ø–æ—Ä—Ç–æ–º –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π

**–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã**:
- `metadata` ‚Üí `user_metadata` (reserved name –≤ SQLAlchemy)
- `create_type=True` –¥–ª—è PostgreSQL ENUM —Ç–∏–ø–æ–≤ (retention_policy_enum, finalize_transaction_status_enum)
- `admin-module/app/api/dependencies/auth.py` - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ User model ‚Üí ServiceAccount

---

#### Task 2.2: Retention Policy –≤ Upload API

**–¶–µ–ª—å**: –î–æ–±–∞–≤–∏—Ç—å –ø–æ–¥–¥–µ—Ä–∂–∫—É retention_policy –≤ upload endpoint.

**–ú–æ–¥—É–ª–∏**: `ingester-module`

**Subtasks**:

1. **–û–±–Ω–æ–≤–∏—Ç—å UploadRequest schema**:
   ```python
   # ingester-module/app/schemas/upload.py

   from enum import Enum

   class RetentionPolicy(str, Enum):
       TEMPORARY = "temporary"
       PERMANENT = "permanent"

   class UploadRequest(BaseModel):
       retention_policy: RetentionPolicy = RetentionPolicy.PERMANENT
       ttl_days: Optional[int] = Field(default=30, ge=1, le=365)
       metadata: dict = Field(default_factory=dict)
   ```

2. **–û–±–Ω–æ–≤–∏—Ç—å upload endpoint**:
   ```python
   # ingester-module/app/api/v1/endpoints/upload.py

   @router.post("/upload")
   async def upload_file(
       file: UploadFile,
       request: UploadRequest,
       storage_selector: StorageSelector = Depends(get_storage_selector)
   ):
       # Select SE based on retention_policy
       target_se = await storage_selector.select_storage_element(
           retention_policy=request.retention_policy.value
       )

       # Calculate TTL expiration
       ttl_expires_at = None
       if request.retention_policy == RetentionPolicy.TEMPORARY:
           ttl_expires_at = datetime.utcnow() + timedelta(days=request.ttl_days)

       # Upload to Storage Element
       file_id = await file_service.upload_to_storage(
           file=file,
           storage_element=target_se,
           retention_policy=request.retention_policy,
           ttl_expires_at=ttl_expires_at,
           metadata=request.metadata
       )

       return {"file_id": file_id, "retention_policy": request.retention_policy}
   ```

3. **Integration —Ç–µ—Å—Ç—ã**:
   ```bash
   ingester-module/tests/integration/test_upload_retention_policy.py
   ```
   - Test upload —Å temporary retention
   - Test upload —Å permanent retention
   - Test TTL calculation
   - Test validation (ttl_days range)

**Acceptance Criteria**:
- [x] Upload API –ø—Ä–∏–Ω–∏–º–∞–µ—Ç retention_policy parameter
- [x] TTL –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –¥–ª—è temporary files
- [x] Files –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ SE (edit –∏–ª–∏ rw)
- [ ] Integration —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç —É—Å–ø–µ—à–Ω–æ (TODO: –Ω–∞–ø–∏—Å–∞—Ç—å —Ç–µ—Å—Ç—ã)
- [x] API documentation –æ–±–Ω–æ–≤–ª–µ–Ω–∞ (Swagger UI)

**Estimated Effort**: 4 hours

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã** (Sprint 15):
- `ingester-module/app/schemas/upload.py` - **UPDATED** RetentionPolicy enum, UploadRequest —Å retention_policy –∏ ttl_days
- `ingester-module/app/api/v1/endpoints/upload.py` - **UPDATED** Upload endpoint —Å retention_policy support
- `ingester-module/app/services/upload_service.py` - **UPDATED** –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è retention_policy –≤ upload flow

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**:
- Default retention_policy = "temporary" (–¥–ª—è Edit SE)
- ttl_days –¥–∏–∞–ø–∞–∑–æ–Ω: 1-365 –¥–Ω–µ–π, default 30
- storage_mode deprecated –≤ –ø–æ–ª—å–∑—É retention_policy
- –ú–∞–ø–ø–∏–Ω–≥: temporary ‚Üí edit SE, permanent ‚Üí rw SE

---

#### Task 2.3: Finalize API Endpoint

**–¶–µ–ª—å**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å API –¥–ª—è —Ñ–∏–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ temporary ‚Üí permanent.

**–ú–æ–¥—É–ª–∏**: `ingester-module` –∏–ª–∏ `admin-module` (TBD)

**Subtasks**:

1. **–°–æ–∑–¥–∞—Ç—å FinalizeRequest/Response schemas**:
   ```bash
   ingester-module/app/schemas/finalize.py
   ```

2. **–°–æ–∑–¥–∞—Ç—å FileFinalizationService**:
   ```bash
   ingester-module/app/services/file_finalization_service.py
   ```
   - `start_finalize_transaction()`
   - `copy_to_target()` - Phase 1
   - `verify_and_commit()` - Phase 2
   - `schedule_cleanup()`
   - `rollback_finalize()`

3. **–°–æ–∑–¥–∞—Ç—å endpoint `/api/v1/files/{file_id}/finalize`**:
   ```python
   @router.post("/files/{file_id}/finalize")
   async def finalize_file(
       file_id: str,
       request: FinalizeRequest,
       file_service: FileFinalizationService = Depends(...)
   ):
       # Validation
       file_meta = await file_service.get_file_metadata(file_id)
       if file_meta.retention_policy == RetentionPolicy.PERMANENT:
           raise HTTPException(400, "File is already finalized")

       # Two-Phase Commit
       transaction_id = await file_service.start_finalize_transaction(...)

       try:
           await file_service.copy_to_target(...)
           await file_service.verify_and_commit(...)
           await file_service.schedule_cleanup(...)

           return {"status": "finalized", "transaction_id": transaction_id}
       except Exception as e:
           await file_service.rollback_finalize(transaction_id)
           raise HTTPException(500, f"Finalization failed: {e}")
   ```

4. **Integration —Ç–µ—Å—Ç—ã**:
   ```bash
   ingester-module/tests/integration/test_finalize_api.py
   ```
   - Test successful finalization
   - Test rollback –ø—Ä–∏ checksum mismatch
   - Test –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–ø–æ–≤—Ç–æ—Ä–Ω—ã–π finalize)
   - Test cleanup scheduling

**Acceptance Criteria**:
- [x] POST `/api/v1/finalize/{file_id}` —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ ‚úÖ
- [x] Two-Phase Commit –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç atomicity ‚úÖ
- [x] Checksum verification –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç corruption ‚úÖ
- [x] Cleanup –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –≤ queue ‚úÖ
- [ ] Integration —Ç–µ—Å—Ç—ã –ø–æ–∫—Ä—ã–≤–∞—é—Ç –≤—Å–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏ (Sprint 16)
- [x] Transaction log –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –≤ DB ‚úÖ

**Estimated Effort**: 12 hours

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã** (Sprint 15):
- `ingester-module/app/api/v1/endpoints/finalize.py` - **NEW** Finalize API endpoints
- `ingester-module/app/services/finalize_service.py` - **NEW** FinalizeService —Å Two-Phase Commit
- `ingester-module/app/schemas/upload.py` - **UPDATED** FinalizeRequest, FinalizeResponse, FinalizeStatus schemas
- `admin-module/app/models/finalize_transaction.py` - **NEW** FileFinalizeTransaction model
- `admin-module/app/models/cleanup_queue.py` - **NEW** FileCleanupQueue model

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**:
- **Endpoint –∏–∑–º–µ–Ω—ë–Ω**: `/api/v1/finalize/{file_id}` (–≤–º–µ—Å—Ç–æ `/api/v1/files/{file_id}/finalize`)
- **Async Two-Phase Commit**: HTTP 202 Accepted —Å transaction_id –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
- **Status polling**: GET `/api/v1/finalize/{transaction_id}/status` –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
- **Status progression**: COPYING (25%) ‚Üí COPIED (50%) ‚Üí VERIFYING (75%) ‚Üí COMPLETED (100%)
- **Safety margin**: 24 —á–∞—Å–∞ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º –∏–∑ source SE
- **TODO**: Integration —Å Admin Module file registry (MVP –∏—Å–ø–æ–ª—å–∑—É–µ—Ç placeholder –¥–∞–Ω–Ω—ã–µ)

---

### Phase 3: Garbage Collection (Sprint 16)

#### Task 3.1: GarbageCollector Background Job

**–¶–µ–ª—å**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π GC job –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ Edit Storage Elements.

**–ú–æ–¥—É–ª–∏**: `admin-module`

**Subtasks**:

1. **–°–æ–∑–¥–∞—Ç—å GarbageCollector service**:
   ```bash
   admin-module/app/services/garbage_collector.py
   ```
   - `start()` - periodic execution (every 6h)
   - `_run_cleanup_cycle()` - main orchestrator
   - `_cleanup_expired_ttl()` - TTL-based cleanup
   - `_cleanup_finalized_files()` - cleanup –ø–æ—Å–ª–µ finalize
   - `_cleanup_orphaned_files()` - orphaned files cleanup

2. **–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å GC job –≤ main.py**:
   ```python
   # admin-module/app/main.py

   @app.on_event("startup")
   async def startup_event():
       # ... existing

       # Start Garbage Collector
       gc = GarbageCollector(db, redis_client)
       asyncio.create_task(gc.start())
   ```

3. **Prometheus metrics –¥–ª—è GC**:
   ```python
   gc_cleanup_total = Counter(
       "gc_cleanup_total",
       "Total files cleaned by GC",
       ["type"]  # ttl | finalized | orphaned
   )

   gc_cleanup_duration = Histogram(
       "gc_cleanup_duration_seconds",
       "Duration of GC cleanup cycle"
   )
   ```

4. **Unit —Ç–µ—Å—Ç—ã**:
   ```bash
   admin-module/tests/unit/test_garbage_collector.py
   ```
   - Mock DB operations
   - Test TTL expiration logic
   - Test orphaned files detection
   - Test cleanup scheduling

5. **Integration —Ç–µ—Å—Ç—ã**:
   ```bash
   admin-module/tests/integration/test_gc_full_cycle.py
   ```
   - End-to-end test –ø–æ–ª–Ω–æ–≥–æ GC —Ü–∏–∫–ª–∞
   - Test –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å Storage Elements
   - Test cleanup queue processing

**Acceptance Criteria**:
- [x] GC job –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤ ‚úÖ
- [x] TTL-based cleanup —É–¥–∞–ª—è–µ—Ç expired files ‚úÖ
- [x] Finalized files cleanup –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç cleanup queue ‚úÖ
- [x] Orphaned files cleanup —É–¥–∞–ª—è–µ—Ç files –±–µ–∑ DB records ‚úÖ
- [x] Prometheus metrics –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ ‚úÖ
- [x] Unit —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç —É—Å–ø–µ—à–Ω–æ (19/19 passed) ‚úÖ
- [ ] Integration —Ç–µ—Å—Ç—ã (TODO: Sprint 17)

**Estimated Effort**: 10 hours

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã** (Sprint 16):
- `admin-module/app/services/garbage_collector_service.py` - **NEW** GarbageCollectorService —Å —Ç—Ä–µ–º—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏ –æ—á–∏—Å—Ç–∫–∏
- `admin-module/app/core/config.py` - **UPDATED** –î–æ–±–∞–≤–ª–µ–Ω—ã GC settings –≤ SchedulerSettings
- `admin-module/app/core/scheduler.py` - **UPDATED** –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è GC job –≤ APScheduler
- `admin-module/tests/unit/test_garbage_collector.py` - **NEW** Unit —Ç–µ—Å—Ç—ã (19 —Ç–µ—Å—Ç–æ–≤)

**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏**:
- **–¢—Ä–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ—á–∏—Å—Ç–∫–∏**: TTL-based, Finalized files (+24h safety margin), Orphaned files (>7 days grace)
- **Prometheus metrics**: gc_files_cleaned_total, gc_files_failed_total, gc_run_duration_seconds, gc_last_run_timestamp, gc_queue_pending_size
- **Configurable settings**: SCHEDULER_GC_ENABLED, SCHEDULER_GC_INTERVAL_HOURS (default 6), SCHEDULER_GC_BATCH_SIZE (default 100), SCHEDULER_GC_SAFETY_MARGIN_HOURS (default 24), SCHEDULER_GC_ORPHAN_GRACE_DAYS (default 7)
- **HTTP client**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç httpx.AsyncClient –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –Ω–∞ Storage Elements
- **Retry logic**: max_retry_count=3 –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ transient failures

---

#### Task 3.2: Storage Element Delete API

**–¶–µ–ª—å**: –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å API –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –Ω–∞ Storage Element (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GC job).

**–ú–æ–¥—É–ª–∏**: `storage-element`

**Subtasks**:

1. **–°–æ–∑–¥–∞—Ç—å DELETE endpoint**:
   ```bash
   storage-element/app/api/v1/endpoints/files.py
   ```
   ```python
   @router.delete("/files/{file_id}")
   async def delete_file(
       file_id: str,
       current_user: dict = Depends(get_current_user)
   ):
       # Authorization check (—Ç–æ–ª—å–∫–æ service accounts)
       if current_user["type"] != "service_account":
           raise HTTPException(403, "Only service accounts can delete files")

       # Delete physical file
       await file_service.delete_file(file_id)

       # Delete attr.json
       await file_service.delete_attr_file(file_id)

       # Update DB cache (mark as deleted)
       await db.execute(
           "UPDATE file_metadata SET deleted_at = NOW() WHERE file_id = $1",
           file_id
       )

       return {"status": "deleted", "file_id": file_id}
   ```

2. **Audit logging –¥–ª—è delete operations**:
   ```python
   await audit_service.log_event(
       action="file_delete",
       resource_id=file_id,
       user_id=current_user["id"],
       details={"reason": "gc_cleanup"}
   )
   ```

3. **Integration —Ç–µ—Å—Ç—ã**:
   ```bash
   storage-element/tests/integration/test_delete_api.py
   ```
   - Test successful delete
   - Test authorization (—Ç–æ–ª—å–∫–æ service accounts)
   - Test audit logging
   - Test idempotency (delete —É–∂–µ —É–¥–∞–ª—ë–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞)

**Acceptance Criteria**:
- [x] DELETE `/api/v1/gc/{file_id}` —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ ‚úÖ
- [x] Physical file –∏ attr.json —É–¥–∞–ª—è—é—Ç—Å—è (—á–µ—Ä–µ–∑ FileService.delete_file) ‚úÖ
- [x] DB cache —É–¥–∞–ª—è–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é ‚úÖ
- [x] Audit log –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ delete (structured logging) ‚úÖ
- [x] –¢–æ–ª—å–∫–æ service accounts –º–æ–≥—É—Ç —É–¥–∞–ª—è—Ç—å —Ñ–∞–π–ª—ã ‚úÖ
- [x] Unit —Ç–µ—Å—Ç—ã –ø—Ä–æ—Ö–æ–¥—è—Ç —É—Å–ø–µ—à–Ω–æ (12/12 passed) ‚úÖ
- [ ] Integration —Ç–µ—Å—Ç—ã (Sprint 17)

**Estimated Effort**: 4 hours

**–†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã** (Sprint 16):
- `storage-element/app/api/deps/auth.py` - **UPDATED** –î–æ–±–∞–≤–ª–µ–Ω `require_service_account` dependency
- `storage-element/app/api/deps/__init__.py` - **UPDATED** –≠–∫—Å–ø–æ—Ä—Ç ServiceAccount
- `storage-element/app/api/v1/endpoints/gc.py` - **NEW** GC API endpoints (DELETE, GET /exists)
- `storage-element/app/api/v1/router.py` - **UPDATED** –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ GC router
- `storage-element/tests/unit/test_gc_api.py` - **NEW** Unit —Ç–µ—Å—Ç—ã (12 —Ç–µ—Å—Ç–æ–≤)
- `storage-element/tests/integration/test_gc_delete_api.py` - **NEW** Integration —Ç–µ—Å—Ç—ã

**Implementation Notes**:
- **Endpoint**: `DELETE /api/v1/gc/{file_id}` (–æ—Ç–¥–µ–ª—å–Ω—ã–π –æ—Ç –æ—Å–Ω–æ–≤–Ω–æ–≥–æ `/files/{file_id}`)
- **Authorization**: –¢–æ–ª—å–∫–æ Service Accounts —á–µ—Ä–µ–∑ `require_service_account` dependency
- **Idempotency**: –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç `status="already_deleted"` (200 OK)
- **Audit logging**: Structured JSON logs —Å `audit=True` marker
- **Cleanup types**: –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç `ttl_expired`, `finalized`, `orphaned`
- **–°—É—â–µ—Å—Ç–≤—É—é—â–∏–π FileService**: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç `FileService.delete_file` –¥–ª—è WAL protocol

---

### Phase 4: Monitoring & Documentation (Sprint 17)

#### Task 4.1: Prometheus Metrics

**–¶–µ–ª—å**: –î–æ–±–∞–≤–∏—Ç—å comprehensive metrics –¥–ª—è monitoring –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.

**–ú–æ–¥—É–ª–∏**: –í—Å–µ –º–æ–¥—É–ª–∏

**Metrics**:

```python
# Ingester Module
storage_selection_duration = Histogram(
    "storage_selection_duration_seconds",
    "Duration of storage element selection"
)

storage_selection_total = Counter(
    "storage_selection_total",
    "Total storage selections",
    ["retention_policy", "status"]  # status: success | fallback | failed
)

storage_unavailable_total = Counter(
    "storage_unavailable_total",
    "Total times no storage was available",
    ["retention_policy"]
)

# File Finalization
file_finalize_duration = Histogram(
    "file_finalize_duration_seconds",
    "Duration of file finalization"
)

file_finalize_total = Counter(
    "file_finalize_total",
    "Total file finalizations",
    ["status"]  # status: success | failed | rollback
)

# Garbage Collector
gc_cleanup_total = Counter(
    "gc_cleanup_total",
    "Total files cleaned by GC",
    ["type"]  # ttl | finalized | orphaned
)

gc_cleanup_duration = Histogram(
    "gc_cleanup_duration_seconds",
    "Duration of GC cleanup cycle"
)

# Storage Element Health
storage_element_capacity_percent = Gauge(
    "storage_element_capacity_percent",
    "Storage element capacity usage percentage",
    ["se_id", "mode"]
)

storage_element_health_status = Gauge(
    "storage_element_health_status",
    "Storage element health status (1=healthy, 0=unhealthy)",
    ["se_id"]
)
```

**Acceptance Criteria**:
- [ ] –í—Å–µ metrics —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è –Ω–∞ `/metrics` endpoint
- [ ] Metrics –¥–æ—Å—Ç—É–ø–Ω—ã –≤ Prometheus
- [ ] Grafana dashboard —Å–æ–∑–¥–∞–Ω –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏

**Estimated Effort**: 4 hours

---

#### Task 4.2: Grafana Dashboard

**–¶–µ–ª—å**: –°–æ–∑–¥–∞—Ç—å Grafana dashboard –¥–ª—è monitoring storage lifecycle.

**Subtasks**:

1. **–°–æ–∑–¥–∞—Ç—å dashboard JSON**:
   ```bash
   monitoring/grafana/dashboards/storage-lifecycle.json
   ```

2. **–ü–∞–Ω–µ–ª–∏**:
   - Storage Element Capacity (–ø–æ SE)
   - Storage Selection Success Rate
   - Finalization Success Rate
   - GC Cleanup Statistics
   - Storage Unavailability Alerts
   - Two-Phase Commit Transaction Status

3. **Import dashboard –≤ Grafana**:
   ```bash
   # Via provisioning
   monitoring/grafana/provisioning/dashboards/storage-lifecycle.yaml
   ```

**Acceptance Criteria**:
- [ ] Dashboard –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –≤—Å–µ key metrics
- [ ] –ü–∞–Ω–µ–ª–∏ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è –≤ real-time
- [ ] Dashboard –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ Grafana

**Estimated Effort**: 3 hours

---

#### Task 4.3: Documentation Updates

**–¶–µ–ª—å**: –û–±–Ω–æ–≤–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è –Ω–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.

**Subtasks**:

1. **–û–±–Ω–æ–≤–∏—Ç—å README.md**:
   - –°–µ–∫—Ü–∏—è "Storage Element Selection Strategy"
   - –°–µ–∫—Ü–∏—è "File Lifecycle Management"
   - –î–∏–∞–≥—Ä–∞–º–º—ã Sequential Fill –∏ Two-Phase Commit

2. **–û–±–Ω–æ–≤–∏—Ç—å –º–æ–¥—É–ª—å–Ω—ã–µ README.md**:
   - `ingester-module/README.md` - Storage Selector
   - `storage-element/README.md` - Health Reporting
   - `admin-module/README.md` - GC Job

3. **–û–±–Ω–æ–≤–∏—Ç—å API documentation**:
   - Swagger UI descriptions –¥–ª—è –Ω–æ–≤—ã—Ö endpoints
   - Examples –¥–ª—è retention_policy –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

4. **–°–æ–∑–¥–∞—Ç—å Architecture Decision Records (ADR)**:
   ```bash
   docs/adr/014-sequential-fill-strategy.md
   docs/adr/015-retention-policy-model.md
   docs/adr/016-two-phase-commit-finalization.md
   ```

**Acceptance Criteria**:
- [ ] README.md –æ–±–Ω–æ–≤–ª—ë–Ω —Å –Ω–æ–≤—ã–º–∏ —Å–µ–∫—Ü–∏—è–º–∏
- [ ] API documentation –∞–∫—Ç—É–∞–ª—å–Ω–∞
- [ ] ADR –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä—É—é—Ç key architectural decisions
- [ ] –î–∏–∞–≥—Ä–∞–º–º—ã –≤–∫–ª—é—á–µ–Ω—ã –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é

**Estimated Effort**: 6 hours

---

## Testing Strategy

### Unit Tests

| Module | Test Coverage Target | Key Areas |
|--------|---------------------|-----------|
| Storage Element | ‚â•90% | HealthReporter, capacity calculation |
| Ingester Module | ‚â•90% | StorageSelector, fallback logic |
| Admin Module | ‚â•90% | GarbageCollector, finalization service |

### Integration Tests

| Scenario | Description | Success Criteria |
|----------|-------------|------------------|
| **Sequential Fill** | Upload –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–∞–π–ª–æ–≤, verify SE selection order | –§–∞–π–ª—ã –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –≤ SE –ø–æ priority |
| **Fallback** | Redis unavailable, verify fallback to Admin Module | Upload —É—Å–ø–µ—à–µ–Ω —á–µ—Ä–µ–∑ Admin API |
| **Finalization** | Upload temporary file, finalize to permanent | Two-Phase Commit —É—Å–ø–µ—à–µ–Ω, cleanup scheduled |
| **GC Cleanup** | Expire temporary file, wait for GC cycle | File —É–¥–∞–ª—ë–Ω –∏–∑ Edit SE |
| **Capacity Threshold** | Fill SE –¥–æ 95%, verify new SE selection | Ingester –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π SE |

### End-to-End Tests

| Workflow | Description | Validation |
|----------|-------------|------------|
| **Full Lifecycle** | Upload temporary ‚Üí Finalize ‚Üí GC cleanup | File –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –≤—Å–µ —ç—Ç–∞–ø—ã –±–µ–∑ –æ—à–∏–±–æ–∫ |
| **Concurrent Uploads** | –ù–µ—Å–∫–æ–ª—å–∫–æ Ingester –ø–∏—à—É—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ | Sequential Fill —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ |
| **SE Failure** | –û—Ç–∫–ª—é—á–∏—Ç—å SE, verify system resilience | –°–∏—Å—Ç–µ–º–∞ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ backup SE |

---

## Rollout Plan

### Sprint 14: Redis Registry & Selection (Week 1-2) ‚úÖ COMPLETED

**Deliverables**:
- [x] HealthReporter –≤ Storage Element
- [x] StorageSelector –≤ Ingester Module
- [x] Admin Module fallback API
- [x] Prometheus metrics –¥–ª—è capacity monitoring (bonus)
- [ ] Unit –∏ integration —Ç–µ—Å—Ç—ã (TODO)

**Deployment**:
1. Deploy updated Storage Element (backward compatible)
2. Deploy Admin Module —Å fallback API
3. Deploy Ingester Module —Å StorageSelector
4. Monitor Redis registry population
5. Verify Sequential Fill behaviour

**Rollback Plan**:
- Ingester fallback –Ω–∞ hardcoded SE list
- Admin Module rollback –∫ previous version

---

### Sprint 15: Retention Policy & Lifecycle (Week 3-4) - ‚úÖ COMPLETED

**Deliverables**:
- [x] Database migrations –¥–ª—è retention_policy ‚úÖ
- [x] Upload API —Å retention_policy support ‚úÖ
- [x] Finalize API endpoint ‚úÖ
- [x] Two-Phase Commit implementation ‚úÖ
- [ ] Integration —Ç–µ—Å—Ç—ã (–ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã –≤ Sprint 16)

**Implemented Files**:
- `admin-module/alembic/versions/20251201_0002_add_retention_policy_and_lifecycle.py`
- `admin-module/app/models/file.py`, `finalize_transaction.py`, `cleanup_queue.py`
- `ingester-module/app/api/v1/endpoints/finalize.py`
- `ingester-module/app/services/finalize_service.py`
- `ingester-module/app/schemas/upload.py` (updated)

**Deployment** (COMPLETED 2024-12-02):
1. ‚úÖ Applied database migrations (backward compatible)
2. ‚úÖ Deployed Ingester Module —Å retention_policy API
3. ‚úÖ Deployed Admin Module —Å finalization models
4. ‚è≥ Monitor finalization success rate (pending integration tests)
5. ‚è≥ Verify cleanup queue population (pending GC implementation)

**Rollback Plan**:
- Retention policy defaults to "permanent"
- Finalize API disabled via feature flag

---

### Sprint 16: Garbage Collection (Week 5-6) - ‚úÖ COMPLETED

**Deliverables**:
- [x] GarbageCollector background job ‚úÖ (Task 3.1 DONE)
- [x] Storage Element delete API (Task 3.2 DONE)
- [x] Cleanup queue processing ‚úÖ (included in Task 3.1)
- [x] Unit —Ç–µ—Å—Ç—ã ‚úÖ (19/19 passed)
- [ ] Integration —Ç–µ—Å—Ç—ã (Sprint 17)

**Deployment**:
1. Deploy Storage Element —Å delete API
2. Deploy Admin Module —Å GC job
3. Monitor GC cleanup metrics
4. Verify no data loss during cleanup

**Rollback Plan**:
- Disable GC job via config flag
- Manual cleanup —á–µ—Ä–µ–∑ Admin API

---

### Sprint 17: Monitoring & Documentation (Week 7)

**Deliverables**:
- [ ] Prometheus metrics
- [ ] Grafana dashboard
- [ ] Updated documentation
- [ ] ADR documents

**Deployment**:
1. Deploy metrics to all modules
2. Import Grafana dashboard
3. Publish updated documentation
4. Conduct team training session

---

## Success Metrics

### Performance Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Storage Selection Latency** | < 50ms (p95) | Prometheus histogram |
| **Finalization Duration** | < 30s for 1GB file (p95) | Prometheus histogram |
| **GC Cleanup Throughput** | ‚â• 1000 files/hour | Prometheus counter |
| **Storage Unavailability Rate** | < 0.1% | Prometheus counter / total uploads |

### Reliability Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Sequential Fill Correctness** | 100% | Manual verification + integration tests |
| **Finalization Success Rate** | ‚â• 99.9% | Prometheus counter (success / total) |
| **Data Integrity (checksum match)** | 100% | Transaction log analysis |
| **GC False Positive Rate** | 0% | Audit log review |

### Operational Metrics

| Metric | Target | Measurement |
|--------|--------|-------------|
| **Redis Availability** | ‚â• 99.9% | Uptime monitoring |
| **Fallback Frequency** | < 1% | Prometheus counter (fallback / total) |
| **Edit SE Capacity Utilization** | 70-90% | Prometheus gauge |
| **RW SE Capacity Utilization** | 80-95% | Prometheus gauge |

---

## Risk Assessment

### High Risk

| Risk | Impact | Mitigation |
|------|--------|------------|
| **Data loss –ø—Ä–∏ finalization** | High | Two-Phase Commit —Å checksum verification, 24h safety margin |
| **GC —É–¥–∞–ª—è–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ —Ñ–∞–π–ª—ã** | High | 7-day grace period –¥–ª—è orphaned files, audit logging |
| **Sequential Fill –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç** | Medium | Fallback –Ω–∞ Admin Module, comprehensive testing |

### Medium Risk

| Risk | Impact | Mitigation |
|------|--------|------------|
| **Redis unavailability** | Medium | Fallback –Ω–∞ Admin Module HTTP API |
| **Storage Element capacity exhausted** | Medium | Alert + Reject, 95% threshold –¥–ª—è early warning |
| **Performance degradation –ø—Ä–∏ GC** | Low | Batch processing, 6-hour interval |

### Low Risk

| Risk | Impact | Mitigation |
|------|--------|------------|
| **Clock skew –≤–ª–∏—è–µ—Ç –Ω–∞ TTL** | Low | Use UTC timestamps, reasonable TTL margins (30 days) |
| **Race condition –≤ Sequential Fill** | Low | Acceptable behaviour, capacity monitoring fixes drift |

---

## Maintenance & Operations

### Monitoring Alerts

```yaml
# Prometheus AlertManager rules

- alert: StorageUnavailable
  expr: rate(storage_unavailable_total[5m]) > 0
  for: 1m
  severity: critical
  annotations:
    summary: "No available storage for uploads"

- alert: FinalizationFailureRate
  expr: |
    rate(file_finalize_total{status="failed"}[10m]) /
    rate(file_finalize_total[10m]) > 0.01
  for: 5m
  severity: warning
  annotations:
    summary: "Finalization failure rate > 1%"

- alert: GCCleanupStuck
  expr: |
    time() - gc_cleanup_last_success_timestamp > 7200
  for: 10m
  severity: warning
  annotations:
    summary: "GC cleanup hasn't run successfully in 2 hours"

- alert: StorageElementCapacityHigh
  expr: storage_element_capacity_percent > 90
  for: 15m
  severity: warning
  annotations:
    summary: "Storage Element {{ $labels.se_id }} capacity > 90%"
```

### Operational Runbooks

#### Runbook 1: Storage Unavailable Alert

**Symptoms**: Upload requests failing with 503 errors

**Investigation**:
1. Check Prometheus: `storage_unavailable_total` counter
2. Check Redis: `redis-cli ZRANGE storage:rw:by_priority 0 -1`
3. Check Storage Element capacity: `storage_element_capacity_percent` gauge

**Resolution**:
1. If capacity exhausted: Add new Storage Element or expand existing
2. If Redis unavailable: Restart Redis, verify fallback to Admin Module
3. If all SE unhealthy: Investigate SE health issues

---

#### Runbook 2: Finalization Failures

**Symptoms**: High rate of finalization failures

**Investigation**:
1. Check transaction log: `SELECT * FROM file_finalize_transactions WHERE status = 'failed' ORDER BY created_at DESC LIMIT 10`
2. Check error messages: `error_message` column
3. Check network connectivity between Edit SE and RW SE

**Resolution**:
1. If checksum mismatch: Investigate storage corruption, retry finalization
2. If network issues: Check SE health status, verify endpoints
3. Manual intervention: Use Admin API to retry failed transactions

---

#### Runbook 3: GC Not Running

**Symptoms**: `GCCleanupStuck` alert firing

**Investigation**:
1. Check Admin Module logs: `docker-compose logs -f admin-module | grep "GC"`
2. Check GC metrics: `gc_cleanup_duration_seconds`, `gc_cleanup_total`
3. Check DB connectivity and Redis health

**Resolution**:
1. If Admin Module crashed: Restart container
2. If DB locked: Check for long-running transactions
3. Manual cleanup: Use `/api/v1/admin/cleanup/trigger` endpoint

---

## Appendix

### A. Redis Commands for Debugging

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ç—É—Å Storage Elements
redis-cli HGETALL storage:elements:se-1

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å RW priority queue
redis-cli ZRANGE storage:rw:by_priority 0 -1 WITHSCORES

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å Edit priority queue
redis-cli ZRANGE storage:edit:by_priority 0 -1 WITHSCORES

# –£–¥–∞–ª–∏—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–∏–π SE
redis-cli ZREM storage:rw:by_priority se-1
redis-cli DEL storage:elements:se-1
```

### B. Database Queries for Debugging

```sql
-- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å pending finalization transactions
SELECT * FROM file_finalize_transactions
WHERE status IN ('copying', 'copied')
ORDER BY created_at DESC;

-- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å cleanup queue
SELECT * FROM file_cleanup_queue
WHERE processed_at IS NULL AND scheduled_at < NOW()
ORDER BY scheduled_at ASC;

-- –ü—Ä–æ–≤–µ—Ä–∏—Ç—å expired TTL files
SELECT file_id, created_at, ttl_expires_at
FROM files
WHERE retention_policy = 'temporary'
  AND ttl_expires_at < NOW()
  AND deleted_at IS NULL;

-- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ retention policies
SELECT retention_policy, COUNT(*) as count,
       AVG(EXTRACT(EPOCH FROM (NOW() - created_at))/86400) as avg_age_days
FROM files
WHERE deleted_at IS NULL
GROUP BY retention_policy;
```

### C. API Examples

```bash
# Upload temporary file
curl -X POST http://localhost:8020/api/v1/upload \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@document.pdf" \
  -F "retention_policy=temporary" \
  -F "ttl_days=30"

# Upload permanent file
curl -X POST http://localhost:8020/api/v1/upload \
  -H "Authorization: Bearer $TOKEN" \
  -F "file=@document.pdf" \
  -F "retention_policy=permanent"

# Finalize temporary file
curl -X POST http://localhost:8020/api/v1/files/{file_id}/finalize \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"target_retention_policy": "permanent"}'

# Get Storage Elements (Admin fallback API)
curl -X GET "http://localhost:8000/api/v1/storage-elements?mode=rw&available=true&order_by=priority" \
  -H "Authorization: Bearer $TOKEN"

# Trigger manual GC cleanup (Admin API)
curl -X POST http://localhost:8000/api/v1/admin/cleanup/trigger \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"cleanup_type": "ttl"}'
```

---

## Changelog

| Date | Version | Changes | Author |
|------|---------|---------|--------|
| 2025-12-01 | 1.0 | Initial version | Claude + User |
| 2025-12-01 | 1.1 | –ê–∫—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è: Adaptive capacity thresholds, multi-level alerting, intelligent file size handling, comprehensive monitoring & forecasting | Claude + User |
| 2025-12-01 | 1.2 | **Sprint 14 IMPLEMENTED**: HealthReporter, StorageSelector, Admin Module internal API, Prometheus metrics. Updated acceptance criteria, added implementation notes | Claude + User |
| 2025-12-02 | 1.3 | **Sprint 16 Task 3.1 IMPLEMENTED**: GarbageCollectorService —Å —Ç—Ä–µ–º—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏ –æ—á–∏—Å—Ç–∫–∏ (TTL, Finalized, Orphaned), Prometheus metrics, APScheduler integration, 19 unit tests passed | Claude + User |
| 2025-12-02 | 1.4 | **Sprint 16 Task 3.2 IMPLEMENTED**: Storage Element GC Delete API (`DELETE /api/v1/gc/{file_id}`), require_service_account dependency, idempotent delete, audit logging, 12 unit tests passed | Claude + User |

---

## Sign-off

**Prepared by**: Claude Code (AI Assistant)
**Reviewed by**: [To be filled]
**Approved by**: [To be filled]
**Date**: 2025-12-01
